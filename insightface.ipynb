{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "34ad718e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import insightface\n",
    "import pickle\n",
    "import os\n",
    "import mediapipe as mp\n",
    "from insightface.app import FaceAnalysis\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b9b47b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\environment\\Lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py:121: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\User/.insightface\\models\\buffalo_l\\1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\User/.insightface\\models\\buffalo_l\\2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\User/.insightface\\models\\buffalo_l\\det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\User/.insightface\\models\\buffalo_l\\genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\User/.insightface\\models\\buffalo_l\\w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (640, 640)\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "detector = FaceAnalysis(name=\"buffalo_l\",  providers=['CUDAExecutionProvider'])\n",
    "detector.prepare(ctx_id=0, det_size=(640, 640), det_thresh=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d624e6",
   "metadata": {},
   "source": [
    "# Data Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2895f28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image repository path\n",
    "img_repo_path = \"captured_repo/\"\n",
    "\n",
    "# Load camera\n",
    "video = cv.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    original_frame = frame.copy()\n",
    "\n",
    "    faces = detector.get(frame)\n",
    "\n",
    "    for face in faces:\n",
    "        bbox = face.bbox.astype(int)\n",
    "        cv.rectangle(frame, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0, 255, 0), 2)\n",
    "\n",
    "    cv.imshow(\"Face Detection\", frame)\n",
    "\n",
    "    key = cv.waitKey(1) & 0xFF\n",
    "    if key == ord('s'):\n",
    "        if len(faces) != 0:\n",
    "            print(\"Image Captured.\")\n",
    "            cv.imwrite(img_path, original_frame) \n",
    "            break\n",
    "    elif key == ord('q'):\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967214b9",
   "metadata": {},
   "source": [
    "# Image Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46471a3",
   "metadata": {},
   "source": [
    "need to adjust again for the preprocessing step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e1a94e",
   "metadata": {},
   "source": [
    "only need to convert the bgr to rgb, adjust the brightness automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c02132a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(img_path)\n",
    "img_rgb = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "\n",
    "# Contrast enhancement\n",
    "lab = cv.cvtColor(img_rgb, cv.COLOR_RGB2LAB)\n",
    "l, a, b = cv.split(lab)\n",
    "clahe = cv.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "l_clahe = clahe.apply(l)\n",
    "lab_clahe = cv.merge((l_clahe, a, b))\n",
    "img_rgb = cv.cvtColor(lab_clahe, cv.COLOR_LAB2RGB)\n",
    "\n",
    "# Bilateral filter\n",
    "img_rgb = cv.bilateralFilter(img_rgb, d=9, sigmaColor=75, sigmaSpace=75)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9823f5",
   "metadata": {},
   "source": [
    "# Face Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "2a02158b",
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = detector.get(img_rgb)\n",
    "h, w = img.shape[:2]\n",
    "frame_center = np.array([w / 2, h / 2])\n",
    "\n",
    "main_face = min(faces, key=lambda f: np.linalg.norm(\n",
    "    np.array([(f.bbox[0] + f.bbox[2]) / 2, (f.bbox[1] + f.bbox[3]) / 2]) - frame_center\n",
    "))\n",
    "\n",
    "bbox = main_face.bbox.astype(int)\n",
    "blurred_img = cv.GaussianBlur(img_rgb, (51,51),0)\n",
    "mask = np.zeros((h, w), dtype=np.uint8)\n",
    "cv.rectangle(mask, (bbox[0], bbox[1]), (bbox[2], bbox[3]), 255, -1)\n",
    "mask_3ch = cv.merge([mask, mask, mask])\n",
    "result = np.where(mask_3ch == 255, img, blurred_img)\n",
    "\n",
    "cv.imshow(\"Focused Main Face\", result)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9874c2bf",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "2686d6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = main_face.normed_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f309db",
   "metadata": {},
   "source": [
    "# Face Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "35a566b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"processed_data/face_embeddings.pkl\", \"rb\") as file:\n",
    "    embeddings_data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "3b812bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "\n",
    "def find_top_k_matches(query_embedding, embeddings_data, k=5):\n",
    "    similarities = []\n",
    "    for item in embeddings_data:\n",
    "        sim = cosine_similarity(query_embedding, item[\"embedding\"])\n",
    "        similarities.append({\n",
    "            \"id\": item[\"id\"],\n",
    "            \"image_name\": item[\"image_name\"],\n",
    "            \"similarity\": sim,\n",
    "            \"landmarks\": item.get(\"landmarks\", []) \n",
    "        })\n",
    "    return sorted(similarities, key=lambda x: x[\"similarity\"], reverse=True)[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ea3e8e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top matches:\n",
      "ID: 2408866, Similarity: 0.484\n",
      "ID: 2408863, Similarity: 0.218\n"
     ]
    }
   ],
   "source": [
    "top_matches = find_top_k_matches(embedding, embeddings_data, k=2)\n",
    "if top_matches:\n",
    "        print(\"Top matches:\")\n",
    "        for match in top_matches:\n",
    "            print(f\"ID: {match['id']}, Similarity: {match['similarity']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962e3c45",
   "metadata": {},
   "source": [
    "# Post Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "c265fcfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top match: {'id': '2408866', 'image_name': '2408866.jpg', 'similarity': np.float32(0.4835062), 'landmarks': []}\n"
     ]
    }
   ],
   "source": [
    "# Get the top 1 match\n",
    "top1 = top_matches[0]\n",
    "print(f\"Top match: {top1}\")\n",
    "\n",
    "# Load the matched image\n",
    "matched_img = cv.imread(img_path)\n",
    "matched_img_rgb = cv.cvtColor(matched_img, cv.COLOR_BGR2RGB)\n",
    "\n",
    "# Detect faces in the matched image\n",
    "faces = detector.get(matched_img_rgb)\n",
    "\n",
    "if faces:\n",
    "    for face in faces:\n",
    "        # Get bounding box\n",
    "        x1, y1, x2, y2 = face.bbox.astype(int)\n",
    "        \n",
    "        # Draw rectangle\n",
    "        cv.rectangle(matched_img_rgb, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        \n",
    "        # Draw label above the rectangle\n",
    "        label = f\"Top 1: {top1['image_name']} ({top1['similarity']:.2f})\"\n",
    "        cv.putText(matched_img_rgb, label, (x1, y1 - 10),\n",
    "                   cv.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "else:\n",
    "    print(\"No face detected in matched image.\")\n",
    "\n",
    "# Show the image\n",
    "cv.imshow(\"Top 1 Match\", cv.cvtColor(matched_img_rgb, cv.COLOR_RGB2BGR))\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
