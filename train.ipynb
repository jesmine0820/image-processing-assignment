{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b281843",
   "metadata": {},
   "source": [
    "# Face Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a33dc4",
   "metadata": {},
   "source": [
    "## Jesmine Tey Khai Jing - InsightFace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70ca148",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22b71d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py:121: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\User/.insightface\\models\\buffalo_l\\1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\User/.insightface\\models\\buffalo_l\\2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\User/.insightface\\models\\buffalo_l\\det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\User/.insightface\\models\\buffalo_l\\genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\User/.insightface\\models\\buffalo_l\\w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\insightface\\utils\\transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save embeddings to database/face_embeddings.pkl successfully\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import cv2 as cv\n",
    "import pickle\n",
    "import sqlite3\n",
    "import csv\n",
    "from insightface.app import FaceAnalysis\n",
    "\n",
    "# Initialize model\n",
    "detector = FaceAnalysis(providers=['CUDAExecutionProvider'])\n",
    "detector.prepare(ctx_id=0, det_size=(640,640))\n",
    "\n",
    "# Initializer\n",
    "OUTPUT_FILE = \"database/face_embeddings.pkl\"\n",
    "DIRECTORY = \"photos\"\n",
    "INITIAL_DATASET = \"dataset/dataset.csv\"\n",
    "INFO_DATABASE = \"database/information.db\"\n",
    "\n",
    "# Process image function\n",
    "def process_img(folder_path: str, output_file=OUTPUT_FILE):\n",
    "    embeddings_data = []\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            img_path = os.path.join(folder_path, filename)\n",
    "            img = cv.imread(img_path)\n",
    "            if img is None:\n",
    "                print(f\"Warning -> Could not read {filename}\")\n",
    "                continue\n",
    "\n",
    "            img_rgb = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "            faces = detector.get(img_rgb)\n",
    "\n",
    "            if not faces:\n",
    "                print(f\"Warning -> No face found in {filename}\")\n",
    "                continue\n",
    "\n",
    "            # Take the first face embeddings\n",
    "            face = faces[0]\n",
    "            embedding = face.normed_embedding\n",
    "            user_id = os.path.splitext(filename)[0]\n",
    "\n",
    "            embeddings_data.append({\n",
    "                'id': user_id,\n",
    "                'image_name': filename,\n",
    "                'embedding': embedding\n",
    "            })\n",
    "\n",
    "    # Save the embedding to files\n",
    "    with open(output_file, \"wb\") as file:\n",
    "        pickle.dump(embeddings_data, file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    print(f\"Save embeddings to {output_file} successfully\")\n",
    "\n",
    "process_img(DIRECTORY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17945ed4",
   "metadata": {},
   "source": [
    "### Face Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2845ef39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\User/.insightface\\models\\buffalo_l\\1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\User/.insightface\\models\\buffalo_l\\2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\User/.insightface\\models\\buffalo_l\\det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\User/.insightface\\models\\buffalo_l\\genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\User/.insightface\\models\\buffalo_l\\w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (640, 640)\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import cv2 as cv\n",
    "import pickle\n",
    "import time\n",
    "import numpy as np\n",
    "from insightface.app import FaceAnalysis\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "# Initializer\n",
    "detector = FaceAnalysis(name=\"buffalo_l\", providers=['CUDAExecutionProvider'])\n",
    "detector.prepare(ctx_id=0, det_size=(640, 640), det_thresh=0.5)\n",
    "\n",
    "# Load saved embeddings\n",
    "file_path = \"database/face_embeddings.pkl\"\n",
    "with open(file_path, \"rb\") as f:\n",
    "    embeddings_data = pickle.load(f)\n",
    "\n",
    "# Smoother Class\n",
    "class RecognitionSmoother:\n",
    "    def __init__(self, window_size=5):\n",
    "        self.window_size = window_size\n",
    "        self.history = []\n",
    "    \n",
    "    def add_recognition(self, person_id, score):\n",
    "        self.history.append((person_id, score))\n",
    "        if len(self.history) > self.window_size:\n",
    "            self.history.pop(0)\n",
    "    \n",
    "    def get_smoothed_result(self):\n",
    "        if not self.history:\n",
    "            return None, 0\n",
    "\n",
    "        weights = np.linspace(0.5, 1.5, len(self.history))\n",
    "        scores = {}\n",
    "        \n",
    "        for (pid, score), weight in zip(self.history, weights):\n",
    "            if pid not in scores:\n",
    "                scores[pid] = []\n",
    "            scores[pid].append(score * weight)\n",
    "        \n",
    "        avg_scores = {pid: np.mean(vals) for pid, vals in scores.items()}\n",
    "        best_pid = max(avg_scores.items(), key=lambda x: x[1])[0]\n",
    "        best_score = avg_scores[best_pid]\n",
    "        \n",
    "        return best_pid, best_score\n",
    "    \n",
    "# Initialize smoother\n",
    "smoother = RecognitionSmoother(window_size=5)\n",
    "\n",
    "# Initialize camera\n",
    "video = cv.VideoCapture(0)\n",
    "\n",
    "# Get embeddings\n",
    "def get_face_embedding_from_obj(face_obj):\n",
    "    emb = face_obj.embedding\n",
    "    if emb is None:\n",
    "        return None\n",
    "    return emb / np.linalg.norm(emb)\n",
    "\n",
    "# Use Cosine similarity\n",
    "def recognize_face(embedding, dataset, threshold=0.5):\n",
    "    if embedding is None:\n",
    "        return None, None, -1\n",
    "\n",
    "    best_score = -1\n",
    "    best_id = None\n",
    "    best_name = None\n",
    "\n",
    "    for entry in dataset:\n",
    "        db_embedding = entry[\"embedding\"]\n",
    "        db_embedding = db_embedding / np.linalg.norm(db_embedding)\n",
    "\n",
    "        cos_sim = np.dot(embedding, db_embedding)\n",
    "        if cos_sim > best_score:\n",
    "            best_score = cos_sim\n",
    "            best_id = entry[\"id\"]\n",
    "            best_name = entry[\"image_name\"]\n",
    "\n",
    "    if best_score < threshold:\n",
    "        return None, None, best_score\n",
    "\n",
    "    return best_id, best_name, best_score\n",
    "\n",
    "# Draw rectangle on the face\n",
    "def draw_result(image, name, score):\n",
    "    faces = detector.get(image)\n",
    "    if not faces:\n",
    "        return image\n",
    "\n",
    "    h, w, _ = image.shape\n",
    "    img_center = np.array([w // 2, h // 2])\n",
    "    closest_face, min_dist = None, float(\"inf\")\n",
    "\n",
    "    for face in faces:\n",
    "        bbox = face.bbox.astype(int)\n",
    "        face_center = np.array([(bbox[0] + bbox[2]) // 2, (bbox[1] + bbox[3]) // 2])\n",
    "        dist = np.linalg.norm(face_center - img_center)\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            closest_face = face\n",
    "\n",
    "    if closest_face is None:\n",
    "        return image\n",
    "\n",
    "    bbox = closest_face.bbox.astype(int)\n",
    "    cv.rectangle(image, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0, 255, 0), 2)\n",
    "\n",
    "    label = f\"{name} ({score:.2f})\" if name else \"Unknown\"\n",
    "    cv.putText(image, label, (bbox[0], bbox[1] - 10),\n",
    "               cv.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "    return image\n",
    "\n",
    "def real_time_pipeline():\n",
    "    current_person = None\n",
    "    start_time = None\n",
    "\n",
    "    while True:\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame = cv.flip(frame, 1)\n",
    "        rgb_frame = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "\n",
    "        faces = detector.get(rgb_frame)\n",
    "\n",
    "        if faces:\n",
    "            # pick best face (highest det_score)\n",
    "            faces.sort(key=lambda f: f.det_score, reverse=True)\n",
    "            best_face = faces[0]\n",
    "\n",
    "            # face quality filtering\n",
    "            if best_face.det_score < 0.6:\n",
    "                continue\n",
    "            if (best_face.bbox[2] - best_face.bbox[0]) < 80:\n",
    "                continue\n",
    "\n",
    "            # get embedding\n",
    "            embedding = get_face_embedding_from_obj(best_face)\n",
    "\n",
    "            # recognize\n",
    "            person_id, name, score = recognize_face(embedding, embeddings_data)\n",
    "\n",
    "            # smooth results\n",
    "            smoother.add_recognition(person_id, score)\n",
    "            smoothed_id, smoothed_score = smoother.get_smoothed_result()\n",
    "\n",
    "            # draw\n",
    "            frame = draw_result(frame, name, smoothed_score)\n",
    "\n",
    "            # stable detection for 5s\n",
    "            if smoothed_id == current_person:\n",
    "                if start_time and (time.time() - start_time >= 5):\n",
    "                    print(f\"Detected id: {smoothed_id}, Score: {smoothed_score}\")\n",
    "                    start_time = None\n",
    "            else:\n",
    "                current_person = smoothed_id\n",
    "                start_time = time.time()\n",
    "\n",
    "        # draw middle guide box\n",
    "        h, w, _ = frame.shape\n",
    "        rect_w, rect_h = 200, 200\n",
    "        center_x, center_y = w // 2, h // 2\n",
    "        top_left = (center_x - rect_w // 2, center_y - rect_h // 2)\n",
    "        bottom_right = (center_x + rect_w // 2, center_y + rect_h // 2)\n",
    "        cv.rectangle(frame, top_left, bottom_right, (255, 0, 0), 2)\n",
    "\n",
    "        cv.imshow(\"Face Recognition\", frame)\n",
    "        if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    video.release()\n",
    "    cv.destroyAllWindows()\n",
    "\n",
    "real_time_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801da8b4",
   "metadata": {},
   "source": [
    "## Ethel Ng Yi Yan - MTCNN with FaceNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ca4521",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13e6ef34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "ðŸ“‚ Loading FaceNet embeddings from database\\facenet_embeddings.pkl\n",
      "âœ… Loaded 22 valid faces from database.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from mtcnn import MTCNN\n",
    "from keras_facenet import FaceNet\n",
    "\n",
    "# Initialize detector and embedder\n",
    "detector = MTCNN()\n",
    "embedder = FaceNet()\n",
    "\n",
    "# Folder containing known faces\n",
    "photo_dir = \"photos\"\n",
    "dataset_dir = \"database\"\n",
    "os.makedirs(dataset_dir, exist_ok=True)\n",
    "pkl_path = os.path.join(dataset_dir, \"facenet_embeddings.pkl\")\n",
    "\n",
    "def l2_normalize(x):\n",
    "    return x / np.linalg.norm(x)\n",
    "\n",
    "# Get embedding from image path\n",
    "def get_face_embedding(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        print(f\"[WARNING] Failed to load image: {img_path}\")\n",
    "        return None\n",
    "    \n",
    "    results = detector.detect_faces(img)\n",
    "    if len(results) == 0:\n",
    "        print(f\"[INFO] No face detected in: {img_path}\")\n",
    "        return None\n",
    "    \n",
    "    face = results[0]\n",
    "    x, y, w, h = face['box']\n",
    "    x, y = max(0, x), max(0, y)\n",
    "    \n",
    "    face_img = img[y:y+h, x:x+w]\n",
    "    face_img = cv2.resize(face_img, (160, 160))\n",
    "    \n",
    "    embedding = embedder.embeddings([face_img])[0]\n",
    "    embedding = l2_normalize(embedding)\n",
    "    return embedding\n",
    "\n",
    "# Build the face database from photo directory\n",
    "def build_face_database(folder):\n",
    "    database = {}\n",
    "    for file in os.listdir(folder):\n",
    "        if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            path = os.path.join(folder, file)\n",
    "            name = os.path.splitext(file)[0]\n",
    "            print(f\"Processing: {file}\")\n",
    "            embedding = get_face_embedding(path)\n",
    "            if embedding is not None:\n",
    "                database[name] = embedding\n",
    "            else:\n",
    "                print(f\"[SKIPPED] {file}\")\n",
    "    return database\n",
    "\n",
    "# Load existing database or create a new one\n",
    "if os.path.exists(pkl_path):\n",
    "    print(f\"ðŸ“‚ Loading FaceNet embeddings from {pkl_path}\")\n",
    "    with open(pkl_path, \"rb\") as f:\n",
    "        face_database = pickle.load(f)\n",
    "else:\n",
    "    print(\"âš¡ Building FaceNet embeddings database...\")\n",
    "    face_database = build_face_database(photo_dir)\n",
    "    with open(pkl_path, \"wb\") as f:\n",
    "        pickle.dump(face_database, f)\n",
    "    print(f\"âœ… Database saved to {pkl_path}\")\n",
    "\n",
    "print(f\"âœ… Loaded {len(face_database)} valid faces from database.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e438261",
   "metadata": {},
   "source": [
    "### Face Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91b9e596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“· Press 'q' to quit...\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Get top N matches with cosine similarity\n",
    "def get_top_matches(face_img, database, top_n=3):\n",
    "    face_img = cv2.resize(face_img, (160, 160))\n",
    "    embedding = embedder.embeddings([face_img])[0]\n",
    "    embedding = l2_normalize(embedding)\n",
    "\n",
    "    similarities = []\n",
    "    for name, db_emb in database.items():\n",
    "        sim_score = cosine_similarity([embedding], [db_emb])[0][0]  # Higher is better\n",
    "        similarities.append((name, sim_score))\n",
    "\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    return similarities[:top_n]\n",
    "\n",
    "def real_time():\n",
    "    # Start webcam recognition with stillness detection\n",
    "    video = cv2.VideoCapture(0)\n",
    "    print(\"ðŸ“· Press 'q' to quit...\")\n",
    "\n",
    "    # Parameters for stillness detection\n",
    "    still_threshold = 10  # max movement in pixels to consider still\n",
    "    still_duration = 2    # seconds to hold still before capture\n",
    "\n",
    "    last_face_pos = None\n",
    "    still_start_time = None\n",
    "    captured = False\n",
    "    top_matches = []\n",
    "\n",
    "    while True:\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        results = detector.detect_faces(frame)\n",
    "\n",
    "        if len(results) == 0:\n",
    "            last_face_pos = None\n",
    "            still_start_time = None\n",
    "            captured = False\n",
    "            top_matches = []\n",
    "        else:\n",
    "            largest_face = max(results, key=lambda f: f['box'][2] * f['box'][3])\n",
    "            x, y, w, h = largest_face['box']\n",
    "            x, y = max(0, x), max(0, y)\n",
    "\n",
    "            if last_face_pos is not None:\n",
    "                lx, ly, lw, lh = last_face_pos\n",
    "                movement = abs(x - lx) + abs(y - ly) + abs(w - lw) + abs(h - lh)\n",
    "            else:\n",
    "                movement = None\n",
    "\n",
    "            if movement is not None and movement < still_threshold:\n",
    "                if still_start_time is None:\n",
    "                    still_start_time = time.time()\n",
    "                else:\n",
    "                    elapsed = time.time() - still_start_time\n",
    "                    remaining = int(still_duration - elapsed) + 1\n",
    "\n",
    "                    countdown_label = f\"Hold still... {remaining}s\"\n",
    "                    (label_width, label_height), baseline = cv2.getTextSize(countdown_label, cv2.FONT_HERSHEY_SIMPLEX, 0.8, 2)\n",
    "                    cv2.rectangle(frame, (x, y - label_height - baseline - 10), (x + label_width, y), (0, 255, 255), cv2.FILLED)\n",
    "                    cv2.putText(frame, countdown_label, (x, y - 5),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), 2)\n",
    "\n",
    "                    if elapsed >= still_duration and not captured:\n",
    "                        margin = 10\n",
    "                        x1 = max(0, x - margin)\n",
    "                        y1 = max(0, y - margin)\n",
    "                        x2 = min(frame.shape[1], x + w + margin)\n",
    "                        y2 = min(frame.shape[0], y + h + margin)\n",
    "                        face_img = frame[y1:y2, x1:x2]\n",
    "\n",
    "                        top_matches = get_top_matches(face_img, face_database)\n",
    "\n",
    "                        print(f\"\\nCaptured face after being still for {still_duration} seconds:\")\n",
    "                        for match_name, sim in top_matches:\n",
    "                            print(f\"  {match_name}: {sim * 100:.2f}% similarity\")\n",
    "\n",
    "                        captured = True\n",
    "            else:\n",
    "                still_start_time = None\n",
    "                captured = False\n",
    "                top_matches = []\n",
    "\n",
    "            last_face_pos = (x, y, w, h)\n",
    "\n",
    "            if captured and top_matches:\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                best_name, best_sim = top_matches[0]\n",
    "                label = f\"{best_name} ({best_sim*100:.1f}%)\"\n",
    "                (label_width, label_height), baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)\n",
    "                cv2.rectangle(frame, (x, y - label_height - baseline - 5), (x + label_width, y), (0, 255, 0), cv2.FILLED)\n",
    "                cv2.putText(frame, label, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n",
    "            else:\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 255), 2)\n",
    "\n",
    "        cv2.imshow('Face Recognition with MTCNN + FaceNet', frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    video.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "real_time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd2322a",
   "metadata": {},
   "source": [
    "# Model Evaluation for Face Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46c0a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py:121: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\User/.insightface\\models\\buffalo_m\\1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\User/.insightface\\models\\buffalo_m\\2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\User/.insightface\\models\\buffalo_m\\det_2.5g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\User/.insightface\\models\\buffalo_m\\genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\User/.insightface\\models\\buffalo_m\\w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (640, 640)\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from insightface.app import FaceAnalysis\n",
    "from mtcnn import MTCNN\n",
    "from keras_facenet import FaceNet\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "name_to_id = {\n",
    "    \"Ethel\": \"24WMR08861\",\n",
    "    \"Jesmine\": \"24WMR08866\",\n",
    "    \"Khaili\": \"24WMR08863\",\n",
    "    \"Kit\": \"24WMR08870\"\n",
    "}\n",
    "id_to_name = {v: k for k, v in name_to_id.items()}\n",
    "\n",
    "with open(\"database/face_embeddings.pkl\", \"rb\") as f:\n",
    "    embeddings_insight = pickle.load(f)\n",
    "\n",
    "with open(\"database/facenet_embeddings.pkl\", \"rb\") as f:\n",
    "    embeddings_facenet = pickle.load(f)\n",
    "\n",
    "insight_detector = FaceAnalysis(name=\"buffalo_m\", providers=['CUDAExecutionProvider'])\n",
    "insight_detector.prepare(ctx_id=0, det_size=(640, 640))\n",
    "\n",
    "mtcnn_detector = MTCNN()\n",
    "facenet = FaceNet()\n",
    "\n",
    "def get_face_embedding_from_obj(face_obj):\n",
    "    emb = face_obj.embedding\n",
    "    if emb is None:\n",
    "        return None\n",
    "    return emb / np.linalg.norm(emb)\n",
    "\n",
    "def recognize_face(embedding, dataset, threshold=0.5):\n",
    "    if embedding is None:\n",
    "        return None, None, -1\n",
    "\n",
    "    best_score = -1\n",
    "    best_id, best_name = None, None\n",
    "\n",
    "    for entry in dataset:\n",
    "        db_embedding = entry[\"embedding\"]\n",
    "        db_embedding = db_embedding / np.linalg.norm(db_embedding)\n",
    "\n",
    "        cos_sim = np.dot(embedding, db_embedding)\n",
    "        if cos_sim > best_score:\n",
    "            best_score = cos_sim\n",
    "            best_id = entry[\"id\"]\n",
    "            best_name = entry[\"image_name\"]\n",
    "\n",
    "    if best_score < threshold:\n",
    "        return None, None, best_score\n",
    "\n",
    "    return best_id, best_name, best_score\n",
    "\n",
    "def get_top_matches(face_img, database, top_n=1, threshold=0.5):\n",
    "    face_img_rgb = cv2.cvtColor(face_img, cv2.COLOR_BGR2RGB)\n",
    "    embeddings = facenet.embeddings([face_img_rgb])\n",
    "    if embeddings is None or len(embeddings) == 0:\n",
    "        return []\n",
    "\n",
    "    query_emb = embeddings[0] / np.linalg.norm(embeddings[0])\n",
    "\n",
    "    scores = []\n",
    "    for entry in database:\n",
    "        db_embedding = entry[\"embedding\"]\n",
    "        db_embedding = db_embedding / np.linalg.norm(db_embedding)\n",
    "        cos_sim = np.dot(query_emb, db_embedding)\n",
    "        scores.append((entry[\"id\"], cos_sim))\n",
    "\n",
    "    scores = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "    return [s for s in scores if s[1] >= threshold][:top_n]\n",
    "\n",
    "def evaluate_model(test_dir, method=\"insightface\", threshold=0.5):\n",
    "    y_true, y_pred = [], []\n",
    "\n",
    "    if method == \"insightface\":\n",
    "        database = embeddings_insight\n",
    "    elif method == \"mtcnn\":\n",
    "        database = embeddings_facenet\n",
    "    else:\n",
    "        raise ValueError(\"Invalid method. Use 'insightface' or 'mtcnn'.\")\n",
    "\n",
    "    for person_name in os.listdir(test_dir):\n",
    "        person_path = os.path.join(test_dir, person_name)\n",
    "        if not os.path.isdir(person_path):\n",
    "            continue\n",
    "\n",
    "        for img_file in os.listdir(person_path):\n",
    "            if not img_file.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "                continue\n",
    "\n",
    "            img_path = os.path.join(person_path, img_file)\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                continue\n",
    "\n",
    "            pred_name = \"Unknown\"\n",
    "\n",
    "            # ---------------- INSIGHTFACE ----------------\n",
    "            if method == \"insightface\":\n",
    "                faces = insight_detector.get(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "                if not faces:\n",
    "                    continue\n",
    "                best_face = max(faces, key=lambda f: f.det_score)\n",
    "                emb = get_face_embedding_from_obj(best_face)\n",
    "                pid, name, score = recognize_face(emb, database, threshold)\n",
    "\n",
    "                pred_name = id_to_name.get(pid, \"Unknown\") if pid else \"Unknown\"\n",
    "\n",
    "            # ---------------- MTCNN + FACENET ----------------\n",
    "            elif method == \"mtcnn\":\n",
    "                results = mtcnn_detector.detect_faces(img)\n",
    "                if len(results) == 0:\n",
    "                    print(f\"[INFO] No face detected in {img_file}\")\n",
    "                    y_true.append(person_name)\n",
    "                    y_pred.append(\"Unknown\")\n",
    "                    continue\n",
    "\n",
    "                # pick largest face\n",
    "                largest = max(results, key=lambda r: r['box'][2] * r['box'][3])\n",
    "                x, y, w, h = largest['box']\n",
    "                x, y = max(0, x), max(0, y)\n",
    "                x2, y2 = min(x+w, img.shape[1]), min(y+h, img.shape[0])\n",
    "                face_img = img[y:y2, x:x2]\n",
    "\n",
    "                try:\n",
    "                    # preprocess for FaceNet\n",
    "                    face_rgb = cv2.cvtColor(face_img, cv2.COLOR_BGR2RGB)\n",
    "                    face_rgb = cv2.resize(face_rgb, (160, 160))\n",
    "\n",
    "                    embeddings = facenet.embeddings([face_rgb])\n",
    "                    if embeddings is None or len(embeddings) == 0:\n",
    "                        print(f\"[WARNING] No embedding for {img_file}\")\n",
    "                        y_true.append(person_name)\n",
    "                        y_pred.append(\"Unknown\")\n",
    "                        continue\n",
    "\n",
    "                    query_emb = embeddings[0] / np.linalg.norm(embeddings[0])\n",
    "\n",
    "                    scores = []\n",
    "                    # handle both dict and list of dicts\n",
    "                    if isinstance(database, dict):\n",
    "                        for pid, db_emb in database.items():\n",
    "                            db_emb = db_emb / np.linalg.norm(db_emb)\n",
    "                            cos_sim = np.dot(query_emb, db_emb)\n",
    "                            scores.append((pid, cos_sim))\n",
    "                    elif isinstance(database, list):\n",
    "                        for entry in database:\n",
    "                            db_emb = entry[\"embedding\"] / np.linalg.norm(entry[\"embedding\"])\n",
    "                            cos_sim = np.dot(query_emb, db_emb)\n",
    "                            scores.append((entry[\"id\"], cos_sim))\n",
    "\n",
    "                    scores.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "                    if scores and scores[0][1] >= threshold:\n",
    "                        matched_id = scores[0][0]\n",
    "                        pred_name = id_to_name.get(matched_id, matched_id)\n",
    "                    else:\n",
    "                        pred_name = \"Unknown\"\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {img_file}: {e}\")\n",
    "                    y_true.append(person_name)\n",
    "                    y_pred.append(\"Unknown\")\n",
    "                    continue\n",
    "\n",
    "            gt_name = person_name\n",
    "            y_true.append(gt_name)\n",
    "            y_pred.append(pred_name)\n",
    "\n",
    "            print(f\"[{method}] GT: {gt_name}, Pred: {pred_name}, File: {img_file}\")\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    return acc, y_true, y_pred\n",
    "\n",
    "# ---------------- RUN TEST ----------------\n",
    "test_dir = \"test_photos\"\n",
    "\n",
    "acc_insight, y_true_insight, y_pred_insight = evaluate_model(test_dir, method=\"insightface\", threshold=0.5)\n",
    "acc_mtcnn, y_true_mtcnn, y_pred_mtcnn = evaluate_model(test_dir, method=\"mtcnn\", threshold=0.5)\n",
    "\n",
    "persons = sorted(set(y_true_insight))\n",
    "data = []\n",
    "for person in persons:\n",
    "    mask_insight = [gt == person for gt in y_true_insight]\n",
    "    acc_person_insight = accuracy_score(\n",
    "        np.array(y_true_insight)[mask_insight],\n",
    "        np.array(y_pred_insight)[mask_insight]\n",
    "    )\n",
    "\n",
    "    mask_mtcnn = [gt == person for gt in y_true_mtcnn]\n",
    "    acc_person_mtcnn = accuracy_score(\n",
    "        np.array(y_true_mtcnn)[mask_mtcnn],\n",
    "        np.array(y_pred_mtcnn)[mask_mtcnn]\n",
    "    )\n",
    "\n",
    "    data.append([person, acc_person_insight, acc_person_mtcnn])\n",
    "\n",
    "data.append([\"Overall\", acc_insight, acc_mtcnn])\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"Person\", \"InsightFace Accuracy\", \"MTCNN+FaceNet Accuracy\"])\n",
    "print(\"\\nAccuracy Comparison Table:\")\n",
    "print(df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e9a1fd",
   "metadata": {},
   "source": [
    "# Barcode Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a29b1c4",
   "metadata": {},
   "source": [
    "## Gan Khai Li - zxing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050e5fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install python-barcode Pillow zxing-cpp qrcode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081834ed",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1a5f7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 54 barcodes generated successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import barcode\n",
    "from barcode.writer import ImageWriter\n",
    "import os\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"dataset/dataset.csv\")\n",
    "\n",
    "# Create output folder for barcodes\n",
    "output_dir = \"database/barcode_zxing\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "count = 0  # counterd\n",
    "\n",
    "Code128 = barcode.get_barcode_class(\"code128\")\n",
    "\n",
    "# Loop through each student and generate barcode\n",
    "for idx, student in df.iterrows():\n",
    "    student_id = str(student[\"StudentID\"])  # ensure string\n",
    "    name = student[\"Name\"].replace(\" \", \"_\")  # safe filename\n",
    "    \n",
    "    # Instantiate the barcode with data\n",
    "    code128 = Code128(student_id, writer=ImageWriter())\n",
    "    \n",
    "    # Save barcode as PNG\n",
    "    filename = os.path.join(output_dir, f\"{student_id}_{name}\")\n",
    "    code128.save(filename)\n",
    "    \n",
    "    count += 1  # increment counter\n",
    "\n",
    "# Final confirmation\n",
    "print(f\"All {count} barcodes generated successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6bcf1e",
   "metadata": {},
   "source": [
    "### Barcode Detection\n",
    "Detect the barcode and generate a new barcode as a token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748a340a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student ID detected: 24WMR08866\n",
      "Student ID detected: 24WMR08866\n",
      "Student ID detected: 24WMR08866\n",
      "Student ID detected: 24WMR08866\n",
      "Student ID detected: 24WMR08866\n",
      "Student ID detected: 24WMR08866\n",
      "Student ID detected: 24WMR08866\n",
      "Student ID detected: 24WMR08866\n",
      "Student ID detected: 24WMR08866\n",
      "Student ID detected: 24WMR08866\n",
      "Student ID detected: 24WMR08866\n",
      "Student ID detected: 24WMR08866\n",
      "Student ID detected: 24WMR08866\n",
      "Student ID detected: 24WMR08866\n",
      "Student ID detected: 24WMR08866\n",
      "Student ID detected: 24WMR08866\n",
      "Student ID detected: 24WMR08866\n",
      "Student ID detected: 24WMR08866\n",
      "Student ID detected: 24WMR08866\n",
      "Student ID detected: 24WMR08866\n",
      "Student ID detected: 24WMR08866\n",
      "Student ID detected: 24WMR08866\n",
      "Student ID detected: 24WMR08866\n",
      "Student ID detected: 24WMR08866\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import zxingcpp\n",
    "import qrcode\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv(\"dataset/dataset.csv\")\n",
    "student_dict = df.set_index(\"StudentID\").to_dict(\"index\")\n",
    "\n",
    "# Open camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "\n",
    "target_w, target_h = 402, 280\n",
    "ret, frame = cap.read()\n",
    "h, w, _ = frame.shape\n",
    "roi_w_ratio = target_w / w\n",
    "roi_h_ratio = target_h / h\n",
    "\n",
    "display_name = \"Awaiting scan...\"\n",
    "display_id = \"\"\n",
    "valid_student = False\n",
    "\n",
    "# Graduation classification function\n",
    "def graduation_level(cgpa):\n",
    "    if cgpa >= 3.67:\n",
    "        return \"Distinction\"\n",
    "    elif cgpa >= 2.67:\n",
    "        return \"Merit\"\n",
    "    elif cgpa >= 2.0:\n",
    "        return \"Pass\"\n",
    "    else:\n",
    "        return \"Fail\"\n",
    "    \n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    h, w, _ = frame.shape\n",
    "    roi_w = int(w * roi_w_ratio)\n",
    "    roi_h = int(h * roi_h_ratio)\n",
    "    roi_x1 = w // 2 - roi_w // 2\n",
    "    roi_y1 = h // 2 - roi_h // 2\n",
    "    roi_x2 = roi_x1 + roi_w\n",
    "    roi_y2 = roi_y1 + roi_h\n",
    "\n",
    "    # Semi-transparent overlay\n",
    "    overlay = frame.copy()\n",
    "    overlay[:] = (0, 0, 0)\n",
    "    frame = cv2.addWeighted(overlay, 0.6, frame, 0.4, 0)\n",
    "    ret2, raw_frame = cap.read()\n",
    "    if ret2:\n",
    "        frame[roi_y1:roi_y2, roi_x1:roi_x2] = raw_frame[roi_y1:roi_y2, roi_x1:roi_x2]\n",
    "\n",
    "    # ROI decoding (barcode)\n",
    "    roi = frame[roi_y1:roi_y2, roi_x1:roi_x2]\n",
    "    gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    results = zxingcpp.read_barcodes(gray)\n",
    "\n",
    "    if results:\n",
    "        student_id = results[0].text.strip()\n",
    "        print(f\"Student ID detected: {student_id}\")\n",
    "\n",
    "        if student_id in student_dict:\n",
    "            info = student_dict[student_id]\n",
    "            display_name = info['Name']\n",
    "            display_id = student_id\n",
    "            valid_student = True\n",
    "        else:\n",
    "            display_name = \"INVALID BARCODE\"\n",
    "            display_id = \"\"\n",
    "            valid_student = False\n",
    "\n",
    "    # Show Name and ID below ROI\n",
    "    cv2.putText(frame, f\"Name: {display_name}\", (roi_x1, roi_y2 + 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0) if valid_student else (0, 0, 255), 2)\n",
    "    cv2.putText(frame, f\"ID: {display_id}\", (roi_x1, roi_y2 + 70),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0) if valid_student else (0, 0, 255), 2)\n",
    "\n",
    "    # ROI box\n",
    "    cv2.rectangle(frame, (roi_x1, roi_y1), (roi_x2, roi_y2), (255, 0, 0), 3)\n",
    "    cv2.imshow(\"Graduation Barcode System - Student Verification\", frame)\n",
    "\n",
    "    if valid_student:\n",
    "        # Generate student QR code (with info + graduation level)\n",
    "        level = graduation_level(info[\"CGPA\"])\n",
    "        qr_data = f\"ID: {student_id}\\nName: {info['Name']}\\nFaculty: {info['Faculty']}\\nGraduation Level: {level}\"\n",
    "\n",
    "        qr = qrcode.QRCode(box_size=10, border=4)\n",
    "        qr.add_data(qr_data)\n",
    "        qr.make(fit=True)\n",
    "        qr_img = qr.make_image(fill_color=\"black\", back_color=\"white\").convert(\"RGB\")\n",
    "        qr_np = np.array(qr_img)\n",
    "\n",
    "        # Save QR code locally (optional)\n",
    "        os.makedirs(\"database/QR_codes\", exist_ok=True)\n",
    "        qr_path = f\"database/QR_codes/{student_id}.png\"\n",
    "        qr_img.save(qr_path)\n",
    "        print(f\"QR code created for {info['Name']} ({student_id})\")\n",
    "        print(f\"File path: {qr_path}\")\n",
    "\n",
    "        # Display QR Code on screen for 20 seconds\n",
    "        start_time = time.time()\n",
    "        while True:\n",
    "            cv2.imshow(\"Graduation QR Code - Please capture this code\", qr_np)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "            if time.time() - start_time > 20:\n",
    "                break\n",
    "        break\n",
    "\n",
    "    elif results and student_id not in student_dict:\n",
    "        # Invalid barcode\n",
    "        cv2.putText(frame, \"Access Denied - Student not recognized as graduate\", (50, 100),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 0, 255), 3)\n",
    "        cv2.imshow(\"Graduation Barcode System - Student Verification\", frame)\n",
    "        print(f\"Invalid Student ID: {student_id}\")\n",
    "        cv2.waitKey(3000)\n",
    "        break\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a8beb3",
   "metadata": {},
   "source": [
    "### Scan Generated Barcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d30eb9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QR Data: 24WMR08866\n",
      "QR Data: 24WMR08866\n",
      "QR Data: 24WMR08866\n",
      "QR Data: 24WMR08866\n",
      "QR Data: 24WMR08866\n",
      "QR Data: 24WMR08866\n",
      "QR Data: 24WMR08866\n",
      "QR Data: 24WMR08866\n",
      "QR Data: 24WMR08866\n",
      "QR Data: 24WeR.@{ï½¶\n",
      "QR Data: ID: 24WMR08866\n",
      "Name: Jesmine Tey Khai Jing \n",
      "Faculty: FOCS\n",
      "Graduation Level: Distinction\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import zxingcpp\n",
    "import numpy as np\n",
    "\n",
    "# Load CSV (must contain: StudentID, Name, Photo, etc.)\n",
    "df = pd.read_csv(\"dataset/dataset.csv\")\n",
    "student_dict = df.set_index(\"StudentID\").to_dict(\"index\")\n",
    "\n",
    "# Open camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "\n",
    "# Target region size\n",
    "target_w, target_h = 402, 280\n",
    "ret, frame = cap.read()\n",
    "h, w, _ = frame.shape\n",
    "roi_w_ratio = target_w / w\n",
    "roi_h_ratio = target_h / h\n",
    "\n",
    "detected = False  # whether a valid QR code has been detected\n",
    "\n",
    "while True:\n",
    "    if detected:\n",
    "        # If a valid QR code has already been detected,\n",
    "        # stop reading from camera and only display details window\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "        continue\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Define region of interest (ROI) in the center\n",
    "    h, w, _ = frame.shape\n",
    "    roi_w = int(w * roi_w_ratio)\n",
    "    roi_h = int(h * roi_h_ratio)\n",
    "    roi_x1 = w // 2 - roi_w // 2\n",
    "    roi_y1 = h // 2 - roi_h // 2\n",
    "    roi_x2 = roi_x1 + roi_w\n",
    "    roi_y2 = roi_y1 + roi_h\n",
    "\n",
    "    # Create semi-transparent overlay\n",
    "    overlay = frame.copy()\n",
    "    overlay[:] = (0, 0, 0)\n",
    "    frame = cv2.addWeighted(overlay, 0.6, frame, 0.4, 0)\n",
    "\n",
    "    # Keep the ROI area clear\n",
    "    ret2, raw_frame = cap.read()\n",
    "    if ret2:\n",
    "        frame[roi_y1:roi_y2, roi_x1:roi_x2] = raw_frame[roi_y1:roi_y2, roi_x1:roi_x2]\n",
    "\n",
    "    # Decode QR inside ROI\n",
    "    roi = frame[roi_y1:roi_y2, roi_x1:roi_x2]\n",
    "    gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    results = zxingcpp.read_barcodes(gray)\n",
    "\n",
    "    display_name = \"Waiting for scan...\"\n",
    "    display_id = \"\"\n",
    "    valid_student = False\n",
    "\n",
    "    if results:\n",
    "        qr_data = results[0].text.strip()\n",
    "        print(\"QR Data:\", qr_data)\n",
    "\n",
    "        if \"ID:\" in qr_data:\n",
    "            student_id = qr_data.split(\"ID:\")[1].split(\"\\n\")[0].strip()\n",
    "            display_id = student_id\n",
    "\n",
    "            if student_id in student_dict:\n",
    "                info = student_dict[student_id]\n",
    "                display_name = info['Name']\n",
    "                valid_student = True\n",
    "                detected = True  # stop further camera reading once valid QR is found\n",
    "\n",
    "                # Create a new window to show photo + QR info\n",
    "                details_img = np.ones((500, 400, 3), dtype=np.uint8) * 255  # white background\n",
    "\n",
    "                # Write QR content\n",
    "                y_offset = 250\n",
    "                for line in qr_data.split(\"\\n\"):\n",
    "                    cv2.putText(details_img, line, (20, y_offset),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2)\n",
    "                    y_offset += 30\n",
    "\n",
    "                cv2.imshow(\"Student Details\", details_img)\n",
    "            else:\n",
    "                display_name = \"INVALID QR\"\n",
    "                valid_student = False\n",
    "\n",
    "    # Display student name and ID on camera window\n",
    "    cv2.putText(frame, f\"Name: {display_name}\", (roi_x1, roi_y2 + 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0) if valid_student else (0, 0, 255), 2)\n",
    "    cv2.putText(frame, f\"ID: {display_id}\", (roi_x1, roi_y2 + 70),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0) if valid_student else (0, 0, 255), 2)\n",
    "\n",
    "    # Draw ROI box\n",
    "    cv2.rectangle(frame, (roi_x1, roi_y1), (roi_x2, roi_y2), (255, 0, 0), 3)\n",
    "    cv2.imshow(\"Student QR Code Scanner\", frame)\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2b96c1",
   "metadata": {},
   "source": [
    "## Kit Chin Jie Ying - PyZbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d51a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pyttsx3 pyzbar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86182303",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a5beef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student Barcode is generated successful and store in database/barcode_zbar.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import barcode\n",
    "from barcode.writer import ImageWriter\n",
    "\n",
    "def generate_barcode(data: str, out_png_path: str, code_type: str = \"code128\") -> str:\n",
    "    folder = os.path.dirname(out_png_path)\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    base_no_ext, _ = os.path.splitext(out_png_path)\n",
    "    code = barcode.get(code_type, str(data), writer=ImageWriter())\n",
    "    return code.save(base_no_ext)\n",
    "\n",
    "def prepare_barcodes(input_csv, output_csv, barcode_folder=\"student_barcodes\"):\n",
    "    df = pd.read_csv(input_csv)\n",
    "\n",
    "    if \"StudentID\" not in df.columns:\n",
    "        raise ValueError(\"CSV dont have row 'StudentID'.\")\n",
    "\n",
    "    os.makedirs(barcode_folder, exist_ok=True)\n",
    "\n",
    "    df[\"Barcode_File\"] = \"\"\n",
    "    for idx, row in df.iterrows():\n",
    "        sid = str(row[\"StudentID\"]).strip()\n",
    "        filename = os.path.join(barcode_folder, f\"{sid}.png\")\n",
    "        barcode_path = generate_barcode(sid, filename)\n",
    "        df.at[idx, \"Barcode_File\"] = barcode_path\n",
    "\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"Student Barcode is generated successful and store in {output_csv}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    prepare_barcodes(\n",
    "        input_csv=\"dataset/dataset.csv\",\n",
    "        output_csv=\"database/barcode_zbar.csv\",\n",
    "        barcode_folder=\"database/barcode_zbar\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93504cd1",
   "metadata": {},
   "source": [
    "### Barcode Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fc7c3a",
   "metadata": {},
   "source": [
    "Scan Student ID and generate new barcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6319bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scan StudentID (press 'q' to exit)\n",
      "Detected StudentID: 24WMR08866\n",
      "QR Ready: zbar_qrcodes\\24WMR08866_Jesmine Tey Khai Jing .png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2 as cv\n",
    "import pandas as pd\n",
    "import qrcode\n",
    "import re\n",
    "import time\n",
    "from pyzbar import pyzbar\n",
    "import numpy as np\n",
    "\n",
    "def safe_filename(s: str) -> str:\n",
    "    return re.sub(r'[\\\\/:*?\"<>|]+', \"_\", s)\n",
    "\n",
    "def generate_qr(data: str, out_file: str):\n",
    "    qr = qrcode.QRCode(version=1, box_size=10, border=4)\n",
    "    qr.add_data(data)\n",
    "    qr.make(fit=True)\n",
    "    qr.make_image(fill=\"black\", back_color=\"white\").save(out_file)\n",
    "\n",
    "def attendance_check(csv_path, qr_csv, qr_folder=\"student_qrcodes\"):\n",
    "    os.makedirs(qr_folder, exist_ok=True)\n",
    "\n",
    "    if os.path.exists(qr_csv):\n",
    "        df = pd.read_csv(qr_csv)\n",
    "    else:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        if \"QRCodePath\" not in df.columns:\n",
    "            df[\"QRCodePath\"] = \"\"\n",
    "\n",
    "    id_lookup = {str(r[\"StudentID\"]).strip(): r.to_dict() for _, r in df.iterrows()}\n",
    "    signed_ids = set()\n",
    "\n",
    "    cap = cv.VideoCapture(0, cv.CAP_DSHOW)\n",
    "    detector = pyzbar\n",
    "\n",
    "    print(\"Scan StudentID (press 'q' to exit)\")\n",
    "\n",
    "    last_qr_time = 0\n",
    "    showing_qr = False\n",
    "    qr_img = None\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            continue\n",
    "\n",
    "        # Convert to grayscale for faster decoding\n",
    "        gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "        barcodes = detector.decode(gray)\n",
    "\n",
    "        for bc in barcodes:\n",
    "            sid = bc.data.decode(\"utf-8\").strip()\n",
    "            print(f\"Detected StudentID: {sid}\")\n",
    "\n",
    "            if sid not in id_lookup:\n",
    "                print(\"Invalid StudentID\")\n",
    "                continue\n",
    "\n",
    "            row = id_lookup[sid]\n",
    "\n",
    "            if sid in signed_ids:\n",
    "                #Already scanned before\n",
    "                print(f\"{row['Name']} already attended.\")\n",
    "                continue\n",
    "            else:\n",
    "                #First scan â†’ generate/show QR\n",
    "                qr_file = row.get(\"QRCodePath\", \"\")\n",
    "\n",
    "                # Handle NaN or invalid path\n",
    "                if pd.isna(qr_file):\n",
    "                    qr_file = \"\"\n",
    "\n",
    "                if not qr_file or not os.path.exists(str(qr_file)):\n",
    "                    content = (\n",
    "                        f\"Name: {row['Name']}\\n\"\n",
    "                        f\"StudentID: {row['StudentID']}\\n\"\n",
    "                        f\"Faculty: {row['Faculty']}\\n\"\n",
    "                        f\"Course: {row['Course']}\\n\"\n",
    "                        f\"CGPA: {row['CGPA']}\"\n",
    "                    )\n",
    "                    qr_file = os.path.join(qr_folder, f\"{sid}_{safe_filename(row['Name'])}.png\")\n",
    "                    generate_qr(content, qr_file)\n",
    "                    df.loc[df[\"StudentID\"].astype(str) == sid, \"QRCodePath\"] = qr_file\n",
    "                    df.to_csv(qr_csv, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "                qr_img = cv.imread(qr_file)\n",
    "                if qr_img is not None:\n",
    "                    showing_qr = True\n",
    "\n",
    "                    #Start countdown only after speech finishes\n",
    "                    last_qr_time = time.time()\n",
    "\n",
    "                signed_ids.add(sid)\n",
    "                print(f\"QR Ready: {qr_file}\")\n",
    "\n",
    "        if showing_qr and qr_img is not None:\n",
    "            elapsed = time.time() - last_qr_time\n",
    "            remaining = max(0, 10 - elapsed)\n",
    "\n",
    "            h, w = qr_img.shape[:2]\n",
    "            extra_space = 100\n",
    "            qr_display = np.ones((h + extra_space, w, 3), dtype=np.uint8) * 255\n",
    "            qr_display[0:h, 0:w] = qr_img\n",
    "\n",
    "            cv.putText(\n",
    "                qr_display,\n",
    "                f\"Countdown: {remaining:.1f} s\",\n",
    "                (10, h + 30),\n",
    "                cv.FONT_HERSHEY_SIMPLEX,\n",
    "                1.0,\n",
    "                (0, 0, 255),\n",
    "                2,\n",
    "                cv.LINE_AA\n",
    "            )\n",
    "\n",
    "            # Progress bar\n",
    "            bar_max_width = w - 20\n",
    "            bar_height = 20\n",
    "            bar_y = h + 60\n",
    "            cv.rectangle(qr_display, (10, bar_y), (10 + bar_max_width, bar_y + bar_height), (200, 200, 200), -1)\n",
    "            bar_width = int(bar_max_width * (remaining / 10))\n",
    "            cv.rectangle(qr_display, (10, bar_y), (10 + bar_width, bar_y + bar_height), (0, 0, 255), -1)\n",
    "\n",
    "            cv.imshow(\"QR Code\", qr_display)\n",
    "\n",
    "            if elapsed > 10:\n",
    "                cv.destroyWindow(\"QR Code\")\n",
    "                showing_qr = False\n",
    "                qr_img = None\n",
    "\n",
    "        cv.imshow(\"Attendance Check\", frame)\n",
    "        if cv.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    attendance_check(\n",
    "        csv_path=\"database/barcode_zbar.csv\",  \n",
    "        qr_csv=\"database/dataset_with_qrcode.csv\",     \n",
    "        qr_folder=\"zbar_qrcodes\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32e41df",
   "metadata": {},
   "source": [
    "### Barcode Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a59b387c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# --- Parse QR Code Text ---\n",
    "def parse_qr_text(qr_text: str) -> dict:\n",
    "    info = {}\n",
    "    for line in str(qr_text).splitlines():\n",
    "        m = re.match(r\"\\s*([^:]+)\\s*:\\s*(.*)\\s*$\", line)\n",
    "        if m:\n",
    "            key = m.group(1).strip()\n",
    "            val = m.group(2).strip()\n",
    "            info[key] = val\n",
    "    return info\n",
    "\n",
    "def _clip(v, lo, hi):\n",
    "    return max(lo, min(int(v), hi))\n",
    "\n",
    "# --- Info Panel Generator ---\n",
    "def make_info_panel(lines, photo_img=None, logo_img=None, panel_size=(480, 480)):\n",
    "    h, w = panel_size\n",
    "    panel = 255 * np.ones((h, w, 3), dtype=np.uint8)  # white background\n",
    "\n",
    "    # --- Add logo (with transparency support) ---\n",
    "    if logo_img is not None:\n",
    "        if logo_img.shape[2] == 4:  # if RGBA (has alpha)\n",
    "            lh, lw = logo_img.shape[:2]\n",
    "            scale = 60 / lh  # fixed height = 60px\n",
    "            new_w, new_h = int(lw * scale), int(lh * scale)\n",
    "            logo_resized = cv.resize(logo_img, (new_w, new_h), interpolation=cv.INTER_AREA)\n",
    "\n",
    "            # split channels\n",
    "            b, g, r, a = cv.split(logo_resized)\n",
    "            logo_rgb = cv.merge((b, g, r))\n",
    "            mask = a.astype(float) / 255.0\n",
    "\n",
    "            x_offset = (w - new_w) // 2\n",
    "            y_offset = 10\n",
    "\n",
    "            roi = panel[y_offset:y_offset+new_h, x_offset:x_offset+new_w]\n",
    "\n",
    "            # alpha blend\n",
    "            for c in range(3):\n",
    "                roi[:, :, c] = (1 - mask) * roi[:, :, c] + mask * logo_rgb[:, :, c]\n",
    "\n",
    "            panel[y_offset:y_offset+new_h, x_offset:x_offset+new_w] = roi\n",
    "\n",
    "        else:\n",
    "            # fallback if no alpha channel\n",
    "            lh, lw = logo_img.shape[:2]\n",
    "            scale = 60 / lh\n",
    "            new_w, new_h = int(lw * scale), int(lh * scale)\n",
    "            logo_resized = cv.resize(logo_img, (new_w, new_h), interpolation=cv.INTER_AREA)\n",
    "            x_offset = (w - new_w) // 2\n",
    "            panel[10:10+new_h, x_offset:x_offset+new_w] = logo_resized\n",
    "\n",
    "\n",
    "\n",
    "    # Draw student photo at top (centered)\n",
    "    if photo_img is not None:\n",
    "        ph, pw = photo_img.shape[:2]\n",
    "        scale = min((h // 3) / ph, (w - 40) / pw)  # max 1/3 of panel height\n",
    "        new_w, new_h = int(pw * scale), int(ph * scale)\n",
    "        photo_resized = cv.resize(photo_img, (new_w, new_h), interpolation=cv.INTER_AREA)\n",
    "        x_offset = (w - new_w) // 2\n",
    "        panel[80:80+new_h, x_offset:x_offset+new_w] = photo_resized\n",
    "        y_text = 80 + new_h + 20\n",
    "    else:\n",
    "        y_text = 100\n",
    "\n",
    "    # Draw info text neatly\n",
    "    for line in lines:\n",
    "        cv.putText(panel, line, (20, y_text), cv.FONT_HERSHEY_SIMPLEX, \n",
    "                   0.7, (0, 0, 0), 2, cv.LINE_AA)\n",
    "        y_text += 35\n",
    "\n",
    "    return panel\n",
    "\n",
    "# --- Main Function ---\n",
    "def scan_and_display_with_yolo_and_fallback(\n",
    "    csv_path: str,\n",
    "    camera_index: int = 0,\n",
    "    window_title: str = \"Graduation Screen\",\n",
    "    qr_class_name: str = \"qrcode\",\n",
    "    conf: float = 0.25,\n",
    "    iou: float = 0.45,\n",
    "    pad: int = 8,\n",
    "    logo_path: str = None\n",
    "):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    has_id = \"StudentID\" in df.columns\n",
    "\n",
    "    id_lookup = {}\n",
    "    if has_id:\n",
    "        id_lookup = {str(r[\"StudentID\"]).strip(): r.to_dict() for _, r in df.iterrows()}\n",
    "\n",
    "    csv_dir = os.path.dirname(os.path.abspath(csv_path))\n",
    "    model = YOLO(\"yolov8n.pt\")\n",
    "    names = model.names\n",
    "    name2id = {v: k for k, v in names.items()} if isinstance(names, dict) else {}\n",
    "\n",
    "    cap = cv.VideoCapture(camera_index, cv.CAP_DSHOW)\n",
    "    if not cap.isOpened():\n",
    "        raise RuntimeError(\"Cannot open camera\")\n",
    "\n",
    "    detector = cv.QRCodeDetector()\n",
    "    cv.namedWindow(window_title, cv.WINDOW_NORMAL)\n",
    "\n",
    "    logo_img = cv.imread(logo_path, cv.IMREAD_UNCHANGED) if logo_path else None\n",
    "    info_panel = make_info_panel([\"Waiting for QR Code...\"], logo_img=logo_img)\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            ok, frame = cap.read()\n",
    "            if not ok:\n",
    "                continue\n",
    "\n",
    "            h, w = frame.shape[:2]\n",
    "            data = None\n",
    "\n",
    "            # Step 1: YOLO detect QR\n",
    "            results = model(frame, conf=conf, iou=iou, verbose=False)\n",
    "            boxes = []\n",
    "            if results and len(results) > 0:\n",
    "                r0 = results[0]\n",
    "                if r0.boxes is not None and len(r0.boxes) > 0:\n",
    "                    xyxy = r0.boxes.xyxy.cpu().numpy()\n",
    "                    cls = r0.boxes.cls.cpu().numpy().astype(int)\n",
    "                    confs = r0.boxes.conf.cpu().numpy()\n",
    "                    for (x1, y1, x2, y2), c, cf in zip(xyxy, cls, confs):\n",
    "                        if qr_class_name in name2id and c != name2id[qr_class_name]:\n",
    "                            continue\n",
    "                        boxes.append((x1, y1, x2, y2, cf))\n",
    "\n",
    "            if boxes:\n",
    "                x1, y1, x2, y2, cf = max(boxes, key=lambda x: x[4])\n",
    "                x1p = _clip(x1 - pad, 0, w - 1)\n",
    "                y1p = _clip(y1 - pad, 0, h - 1)\n",
    "                x2p = _clip(x2 + pad, 0, w - 1)\n",
    "                y2p = _clip(y2 + pad, 0, h - 1)\n",
    "\n",
    "                roi = frame[y1p:y2p, x1p:x2p]\n",
    "                if roi.size > 0:\n",
    "                    data, _, _ = detector.detectAndDecode(roi)\n",
    "                    if not data:\n",
    "                        for scale in (1.5, 2.0):\n",
    "                            roi_big = cv.resize(roi, None, fx=scale, fy=scale, interpolation=cv.INTER_CUBIC)\n",
    "                            data, _, _ = detector.detectAndDecode(roi_big)\n",
    "                            if data:\n",
    "                                break\n",
    "\n",
    "                    if data:\n",
    "                        cv.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (36, 255, 12), 3)\n",
    "\n",
    "            if not data:\n",
    "                data, _, _ = detector.detectAndDecode(frame)\n",
    "\n",
    "            if data:\n",
    "                info = parse_qr_text(data)\n",
    "                lines = []\n",
    "                photo_img = None\n",
    "\n",
    "                if has_id and \"StudentID\" in info:\n",
    "                    sid = str(info[\"StudentID\"]).strip()\n",
    "                    row = id_lookup.get(sid)\n",
    "                    if row is not None:\n",
    "                        lines = [\n",
    "                            f\"Name: {row.get('Name','')}\",\n",
    "                            f\"Student ID: {row.get('StudentID','')}\",\n",
    "                            f\"Faculty: {row.get('Faculty','')}\",\n",
    "                            f\"Course: {row.get('Course','')}\",\n",
    "                            f\"CGPA: {row.get('CGPA','')}\",\n",
    "                            f\"Class: {row.get('CGPA_Class','')}\",\n",
    "                        ]\n",
    "                        if \"Photo\" in row and row[\"Photo\"]:\n",
    "                            photo_path = os.path.join(csv_dir, str(row[\"Photo\"]).replace(\"/\", os.sep))\n",
    "                            if os.path.exists(photo_path):\n",
    "                                photo_img = cv.imread(photo_path)\n",
    "                    else:\n",
    "                        lines = [f\"Unregistered Student ID: {sid}\"]\n",
    "                else:\n",
    "                    lines = [\n",
    "                        f\"Name: {info.get('Name','')}\",\n",
    "                        f\"Student ID: {info.get('StudentID','')}\",\n",
    "                        f\"Faculty: {info.get('Faculty','')}\",\n",
    "                        f\"Course: {info.get('Course','')}\",\n",
    "                        f\"CGPA: {info.get('CGPA','')}\"\n",
    "                    ]\n",
    "\n",
    "                info_panel = make_info_panel(lines, photo_img, logo_img)\n",
    "\n",
    "            cam_resized = cv.resize(frame, (640, 480))\n",
    "            info_resized = cv.resize(info_panel, (480, 480))\n",
    "            combined = np.hstack((cam_resized, info_resized))\n",
    "\n",
    "            cv.imshow(window_title, combined)\n",
    "            k = cv.waitKey(1) & 0xFF\n",
    "            if k == ord('q'):\n",
    "                break\n",
    "\n",
    "    finally:\n",
    "        cap.release()\n",
    "        cv.destroyAllWindows()\n",
    "\n",
    "scan_and_display_with_yolo_and_fallback(\n",
    "    csv_path=\"database/dataset_with_qrcode.csv\",\n",
    "    camera_index=0,\n",
    "    window_title=\"Graduation Screen\",\n",
    "    logo_path=\"static/images/logo.png\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab87a1ef",
   "metadata": {},
   "source": [
    "# Real Time Human Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c024f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ultralytics, deep-sort-realtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefed7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import cv2 as cv\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "\n",
    "def draw_box_with_label(img, tlbr, label, color=(0, 255, 0)):\n",
    "    x1, y1, x2, y2 = map(int, tlbr)\n",
    "    cv.rectangle(img, (x1, y1), (x2, y2), color, 2)\n",
    "    (tw, th), _ = cv.getTextSize(label, cv.FONT_HERSHEY_SIMPLEX, 0.6, 2)\n",
    "    cv.rectangle(img, (x1, y1 - th - 6), (x1 + tw + 6, y1), color, -1)\n",
    "    cv.putText(img, label, (x1 + 3, y1 - 6),\n",
    "                cv.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2)\n",
    "\n",
    "def track_person(model_path=\"yolov8n.pt\", threshold=0.4, camera_index=0):\n",
    "    # Load YOLO\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model = YOLO(model_path)\n",
    "    model.to(device)\n",
    "\n",
    "    # DeepSORT tracker\n",
    "    tracker = DeepSort(\n",
    "        max_age=30,\n",
    "        n_init=3,\n",
    "        max_iou_distance=0.7,\n",
    "        nms_max_overlap=1.0,\n",
    "        max_cosine_distance=0.2,\n",
    "        nn_budget=None,\n",
    "        embedder=\"mobilenet\",\n",
    "        half=torch.cuda.is_available(),\n",
    "        bgr=True,\n",
    "    )\n",
    "\n",
    "    # Init video\n",
    "    video = cv.VideoCapture(camera_index)\n",
    "    fps_smooth = None\n",
    "    person_class_id = 0  # YOLO class for \"person\"\n",
    "\n",
    "    # Accuracy tracking\n",
    "    prev_ids = {}\n",
    "    id_switches = 0\n",
    "    total_tracks = 0\n",
    "\n",
    "    # Right-to-left detection\n",
    "    track_positions = {}  # track_id â†’ [first_x, last_x]\n",
    "\n",
    "    while True:\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame = cv.flip(frame, 1)\n",
    "        t0 = time.time()\n",
    "        h, w, _ = frame.shape\n",
    "\n",
    "        # Detect people (full body)\n",
    "        results = model.predict(frame, conf=threshold, iou=0.45,\n",
    "                                verbose=False, classes=[person_class_id], device=device)\n",
    "\n",
    "        detections = []\n",
    "        if len(results):\n",
    "            r = results[0]\n",
    "            if r.boxes is not None and len(r.boxes) > 0:\n",
    "                for box in r.boxes:\n",
    "                    xyxy = box.xyxy[0].cpu().numpy()\n",
    "                    conf = float(box.conf[0].cpu().numpy())\n",
    "\n",
    "                    # Ensure full body bounding box \n",
    "                    x1, y1, x2, y2 = xyxy\n",
    "                    x1 = max(0, int(x1))\n",
    "                    y1 = max(0, int(y1))\n",
    "                    x2 = min(w, int(x2))\n",
    "                    y2 = min(h, int(y2))\n",
    "                    detections.append([[x1, y1, x2, y2], conf, \"person\"])\n",
    "\n",
    "        # Update tracker\n",
    "        tracks = tracker.update_tracks(detections, frame=frame)\n",
    "\n",
    "        for trk in tracks:\n",
    "            if not trk.is_confirmed() or trk.time_since_update > 0:\n",
    "                continue\n",
    "            track_id = trk.track_id\n",
    "            tlbr = trk.to_tlbr()\n",
    "            x1, y1, x2, y2 = map(int, tlbr)\n",
    "            cx = (x1 + x2) // 2  # center x\n",
    "\n",
    "            # Draw\n",
    "            draw_box_with_label(frame, tlbr, f\"ID {track_id}\")\n",
    "\n",
    "            # Accuracy check \n",
    "            total_tracks += 1\n",
    "            if track_id in prev_ids:\n",
    "                if prev_ids[track_id] != track_id:\n",
    "                    id_switches += 1\n",
    "            prev_ids[track_id] = track_id\n",
    "\n",
    "            # Movement Right -> Left \n",
    "            if track_id not in track_positions:\n",
    "                track_positions[track_id] = [cx, cx]  \n",
    "            else:\n",
    "                track_positions[track_id][1] = cx \n",
    "\n",
    "                start_x, last_x = track_positions[track_id]\n",
    "\n",
    "                if start_x > 0.7 * w and last_x < 0.3 * w:\n",
    "                    print(\"Next person\")\n",
    "                    track_positions.pop(track_id)\n",
    "\n",
    "        # FPS\n",
    "        dt = time.time() - t0\n",
    "        fps = 1.0 / dt if dt > 0 else 0.0\n",
    "        fps_smooth = fps if fps_smooth is None else fps_smooth * 0.9 + fps * 0.1\n",
    "        cv.putText(frame, f\"FPS: {fps_smooth:.1f}\", (10, 30),\n",
    "                   cv.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 2)\n",
    "\n",
    "        # Accuracy display\n",
    "        if total_tracks > 0:\n",
    "            accuracy = 1 - (id_switches / total_tracks)\n",
    "            cv.putText(frame, f\"Accuracy: {accuracy:.2f}\", (10, 60),\n",
    "                       cv.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)\n",
    "\n",
    "        cv.imshow(\"Real Time Human Tracking\", frame)\n",
    "        if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    video.release()\n",
    "    cv.destroyAllWindows()\n",
    "\n",
    "track_person()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
