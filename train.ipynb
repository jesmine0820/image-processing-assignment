{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b281843",
   "metadata": {},
   "source": [
    "# Face Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a33dc4",
   "metadata": {},
   "source": [
    "## Jesmine Tey Khai Jing - InsightFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d9bab92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\User/.insightface\\models\\buffalo_l\\1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\User/.insightface\\models\\buffalo_l\\2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\User/.insightface\\models\\buffalo_l\\det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\User/.insightface\\models\\buffalo_l\\genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\User/.insightface\\models\\buffalo_l\\w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (640, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import pickle\n",
    "import time\n",
    "import numpy as np\n",
    "from insightface.app import FaceAnalysis\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "file_path = hf_hub_download(\n",
    "    repo_id=\"jesmine0820/assignment_face_recognition\",   \n",
    "    filename=\"face_embeddings.pkl\",  \n",
    "    repo_type=\"dataset\"\n",
    ")\n",
    "with open(file_path, \"rb\") as f:\n",
    "    embeddings_data = pickle.load(f)\n",
    "\n",
    "detector = FaceAnalysis(name=\"buffalo_l\", providers=['CUDAExecutionProvider'])\n",
    "detector.prepare(ctx_id=0, det_size=(640, 640), det_thresh=0.5)\n",
    "\n",
    "class RecognitionSmoother:\n",
    "    def __init__(self, window_size=5):\n",
    "        self.window_size = window_size\n",
    "        self.history = []\n",
    "    \n",
    "    def add_recognition(self, person_id, score):\n",
    "        self.history.append((person_id, score))\n",
    "        if len(self.history) > self.window_size:\n",
    "            self.history.pop(0)\n",
    "    \n",
    "    def get_smoothed_result(self):\n",
    "        if not self.history:\n",
    "            return None, 0\n",
    "\n",
    "        weights = np.linspace(0.5, 1.5, len(self.history))\n",
    "        scores = {}\n",
    "        \n",
    "        for (pid, score), weight in zip(self.history, weights):\n",
    "            if pid not in scores:\n",
    "                scores[pid] = []\n",
    "            scores[pid].append(score * weight)\n",
    "        \n",
    "        avg_scores = {pid: np.mean(vals) for pid, vals in scores.items()}\n",
    "        best_pid = max(avg_scores.items(), key=lambda x: x[1])[0]\n",
    "        best_score = avg_scores[best_pid]\n",
    "        \n",
    "        return best_pid, best_score\n",
    "\n",
    "smoother = RecognitionSmoother(window_size=5)\n",
    "\n",
    "def get_face_embedding_from_obj(face_obj):\n",
    "    emb = face_obj.embedding\n",
    "    if emb is None:\n",
    "        return None\n",
    "    return emb / np.linalg.norm(emb)\n",
    "\n",
    "def recognize_face(embedding, dataset, threshold=0.5):\n",
    "    if embedding is None:\n",
    "        return None, None, -1\n",
    "\n",
    "    best_score = -1\n",
    "    best_id = None\n",
    "    best_name = None\n",
    "\n",
    "    for entry in dataset:\n",
    "        db_embedding = entry[\"embedding\"]\n",
    "        db_embedding = db_embedding / np.linalg.norm(db_embedding)\n",
    "\n",
    "        cos_sim = np.dot(embedding, db_embedding)\n",
    "        if cos_sim > best_score:\n",
    "            best_score = cos_sim\n",
    "            best_id = entry[\"id\"]\n",
    "            best_name = entry[\"image_name\"]\n",
    "\n",
    "    if best_score < threshold:\n",
    "        return None, None, best_score\n",
    "\n",
    "    return best_id, best_name, best_score\n",
    "\n",
    "def draw_result(image, name, score):\n",
    "    faces = detector.get(image)\n",
    "    if not faces:\n",
    "        return image\n",
    "\n",
    "    h, w, _ = image.shape\n",
    "    img_center = np.array([w // 2, h // 2])\n",
    "    closest_face, min_dist = None, float(\"inf\")\n",
    "\n",
    "    for face in faces:\n",
    "        bbox = face.bbox.astype(int)\n",
    "        face_center = np.array([(bbox[0] + bbox[2]) // 2, (bbox[1] + bbox[3]) // 2])\n",
    "        dist = np.linalg.norm(face_center - img_center)\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            closest_face = face\n",
    "\n",
    "    if closest_face is None:\n",
    "        return image\n",
    "\n",
    "    bbox = closest_face.bbox.astype(int)\n",
    "    cv.rectangle(image, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0, 255, 0), 2)\n",
    "\n",
    "    label = f\"{name} ({score:.2f})\" if name else \"Unknown\"\n",
    "    cv.putText(image, label, (bbox[0], bbox[1] - 10),\n",
    "               cv.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "    return image\n",
    "\n",
    "video = cv.VideoCapture(0)\n",
    "\n",
    "def real_time_pipeline():\n",
    "    current_person = None\n",
    "    start_time = None\n",
    "\n",
    "    while True:\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame = cv.flip(frame, 1)\n",
    "        rgb_frame = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "\n",
    "        faces = detector.get(rgb_frame)\n",
    "\n",
    "        if faces:\n",
    "            # pick best face (highest det_score)\n",
    "            faces.sort(key=lambda f: f.det_score, reverse=True)\n",
    "            best_face = faces[0]\n",
    "\n",
    "            # face quality filtering\n",
    "            if best_face.det_score < 0.6:\n",
    "                continue\n",
    "            if (best_face.bbox[2] - best_face.bbox[0]) < 80:\n",
    "                continue\n",
    "\n",
    "            # get embedding\n",
    "            embedding = get_face_embedding_from_obj(best_face)\n",
    "\n",
    "            # recognize\n",
    "            person_id, name, score = recognize_face(embedding, embeddings_data)\n",
    "\n",
    "            # smooth results\n",
    "            smoother.add_recognition(person_id, score)\n",
    "            smoothed_id, smoothed_score = smoother.get_smoothed_result()\n",
    "\n",
    "            # draw\n",
    "            frame = draw_result(frame, name, smoothed_score)\n",
    "\n",
    "            # stable detection for 5s\n",
    "            if smoothed_id == current_person:\n",
    "                if start_time and (time.time() - start_time >= 5):\n",
    "                    print(f\"Detected id: {smoothed_id}, Score: {smoothed_score}\")\n",
    "                    start_time = None\n",
    "            else:\n",
    "                current_person = smoothed_id\n",
    "                start_time = time.time()\n",
    "\n",
    "        # draw middle guide box\n",
    "        h, w, _ = frame.shape\n",
    "        rect_w, rect_h = 200, 200\n",
    "        center_x, center_y = w // 2, h // 2\n",
    "        top_left = (center_x - rect_w // 2, center_y - rect_h // 2)\n",
    "        bottom_right = (center_x + rect_w // 2, center_y + rect_h // 2)\n",
    "        cv.rectangle(frame, top_left, bottom_right, (255, 0, 0), 2)\n",
    "\n",
    "        cv.imshow(\"Face Recognition\", frame)\n",
    "        if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    video.release()\n",
    "    cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da3addb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected id: 24WMR08866, Score: 0.573700550198555\n"
     ]
    }
   ],
   "source": [
    "real_time_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801da8b4",
   "metadata": {},
   "source": [
    "## Ethel Ng Yi Yan - MTCNN with FaceNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be999c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ Building FaceNet embeddings database...\n",
      "Processing: 24WMA08802.jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "Processing: 24WMA08803.jpg\n",
      "[INFO] No face detected in: photos\\24WMA08803.jpg\n",
      "[SKIPPED] 24WMA08803.jpg\n",
      "Processing: 24WMH08807.jpg\n",
      "[INFO] No face detected in: photos\\24WMH08807.jpg\n",
      "[SKIPPED] 24WMH08807.jpg\n",
      "Processing: 24WMR08820.jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "Processing: 24WMR08821.jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "Processing: 24WMR08822.jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Processing: 24WMR08824.jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Processing: 24WMR08826.jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "Processing: 24WMR08827.jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Processing: 24WMR08828.jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Processing: 24WMR08829.jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "Processing: 24WMR08831.jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "Processing: 24WMR08832.jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Processing: 24WMR08833.png\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Processing: 24WMR08834.jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Processing: 24WMR08835.jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Processing: 24WMR08837.jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Processing: 24WMR08838.jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Processing: 24WMR08841.jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Processing: 24WMR08843.jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "Processing: 24WMR08861.png\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "Processing: 24WMR08863.jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "Processing: 24WMR08866.jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Processing: 24WMR08870.jpeg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "✅ Database saved to dataset\\facenet_embeddings.pkl\n",
      "✅ Loaded 22 valid faces from database.\n"
     ]
    }
   ],
   "source": [
    "from mtcnn import MTCNN\n",
    "from keras_facenet import FaceNet\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import time\n",
    "\n",
    "# Initialize detector and embedder\n",
    "detector = MTCNN()\n",
    "embedder = FaceNet()\n",
    "\n",
    "def l2_normalize(x):\n",
    "    return x / np.linalg.norm(x)\n",
    "\n",
    "# Folder containing known faces\n",
    "photo_dir = \"photos\"\n",
    "dataset_dir = \"database\"\n",
    "os.makedirs(dataset_dir, exist_ok=True)\n",
    "pkl_path = os.path.join(dataset_dir, \"facenet_embeddings.pkl\")\n",
    "\n",
    "# Get embedding from image path\n",
    "def get_face_embedding(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        print(f\"[WARNING] Failed to load image: {img_path}\")\n",
    "        return None\n",
    "    \n",
    "    results = detector.detect_faces(img)\n",
    "    if len(results) == 0:\n",
    "        print(f\"[INFO] No face detected in: {img_path}\")\n",
    "        return None\n",
    "    \n",
    "    face = results[0]\n",
    "    x, y, w, h = face['box']\n",
    "    x, y = max(0, x), max(0, y)\n",
    "    \n",
    "    face_img = img[y:y+h, x:x+w]\n",
    "    face_img = cv2.resize(face_img, (160, 160))\n",
    "    \n",
    "    embedding = embedder.embeddings([face_img])[0]\n",
    "    embedding = l2_normalize(embedding)\n",
    "    return embedding\n",
    "\n",
    "# Build the face database from photo directory\n",
    "def build_face_database(folder):\n",
    "    database = {}\n",
    "    for file in os.listdir(folder):\n",
    "        if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            path = os.path.join(folder, file)\n",
    "            name = os.path.splitext(file)[0]\n",
    "            print(f\"Processing: {file}\")\n",
    "            embedding = get_face_embedding(path)\n",
    "            if embedding is not None:\n",
    "                database[name] = embedding\n",
    "            else:\n",
    "                print(f\"[SKIPPED] {file}\")\n",
    "    return database\n",
    "\n",
    "# Load existing database or create a new one\n",
    "if os.path.exists(pkl_path):\n",
    "    print(f\"📂 Loading FaceNet embeddings from {pkl_path}\")\n",
    "    with open(pkl_path, \"rb\") as f:\n",
    "        face_database = pickle.load(f)\n",
    "else:\n",
    "    print(\"⚡ Building FaceNet embeddings database...\")\n",
    "    face_database = build_face_database(photo_dir)\n",
    "    with open(pkl_path, \"wb\") as f:\n",
    "        pickle.dump(face_database, f)\n",
    "    print(f\"✅ Database saved to {pkl_path}\")\n",
    "\n",
    "print(f\"✅ Loaded {len(face_database)} valid faces from database.\")\n",
    "\n",
    "# Get top N matches with cosine similarity\n",
    "def get_top_matches(face_img, database, top_n=3):\n",
    "    face_img = cv2.resize(face_img, (160, 160))\n",
    "    embedding = embedder.embeddings([face_img])[0]\n",
    "    embedding = l2_normalize(embedding)\n",
    "\n",
    "    similarities = []\n",
    "    for name, db_emb in database.items():\n",
    "        sim_score = cosine_similarity([embedding], [db_emb])[0][0]  # Higher is better\n",
    "        similarities.append((name, sim_score))\n",
    "\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    return similarities[:top_n]\n",
    "\n",
    "def real_time():\n",
    "    # Start webcam recognition with stillness detection\n",
    "    video = cv2.VideoCapture(0)\n",
    "    print(\"📷 Press 'q' to quit...\")\n",
    "\n",
    "    # Parameters for stillness detection\n",
    "    still_threshold = 10  # max movement in pixels to consider still\n",
    "    still_duration = 2    # seconds to hold still before capture\n",
    "\n",
    "    last_face_pos = None\n",
    "    still_start_time = None\n",
    "    captured = False\n",
    "    top_matches = []\n",
    "\n",
    "    while True:\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        results = detector.detect_faces(frame)\n",
    "\n",
    "        if len(results) == 0:\n",
    "            last_face_pos = None\n",
    "            still_start_time = None\n",
    "            captured = False\n",
    "            top_matches = []\n",
    "        else:\n",
    "            largest_face = max(results, key=lambda f: f['box'][2] * f['box'][3])\n",
    "            x, y, w, h = largest_face['box']\n",
    "            x, y = max(0, x), max(0, y)\n",
    "\n",
    "            if last_face_pos is not None:\n",
    "                lx, ly, lw, lh = last_face_pos\n",
    "                movement = abs(x - lx) + abs(y - ly) + abs(w - lw) + abs(h - lh)\n",
    "            else:\n",
    "                movement = None\n",
    "\n",
    "            if movement is not None and movement < still_threshold:\n",
    "                if still_start_time is None:\n",
    "                    still_start_time = time.time()\n",
    "                else:\n",
    "                    elapsed = time.time() - still_start_time\n",
    "                    remaining = int(still_duration - elapsed) + 1\n",
    "\n",
    "                    countdown_label = f\"Hold still... {remaining}s\"\n",
    "                    (label_width, label_height), baseline = cv2.getTextSize(countdown_label, cv2.FONT_HERSHEY_SIMPLEX, 0.8, 2)\n",
    "                    cv2.rectangle(frame, (x, y - label_height - baseline - 10), (x + label_width, y), (0, 255, 255), cv2.FILLED)\n",
    "                    cv2.putText(frame, countdown_label, (x, y - 5),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), 2)\n",
    "\n",
    "                    if elapsed >= still_duration and not captured:\n",
    "                        margin = 10\n",
    "                        x1 = max(0, x - margin)\n",
    "                        y1 = max(0, y - margin)\n",
    "                        x2 = min(frame.shape[1], x + w + margin)\n",
    "                        y2 = min(frame.shape[0], y + h + margin)\n",
    "                        face_img = frame[y1:y2, x1:x2]\n",
    "\n",
    "                        top_matches = get_top_matches(face_img, face_database)\n",
    "\n",
    "                        print(f\"\\nCaptured face after being still for {still_duration} seconds:\")\n",
    "                        for match_name, sim in top_matches:\n",
    "                            print(f\"  {match_name}: {sim * 100:.2f}% similarity\")\n",
    "\n",
    "                        captured = True\n",
    "            else:\n",
    "                still_start_time = None\n",
    "                captured = False\n",
    "                top_matches = []\n",
    "\n",
    "            last_face_pos = (x, y, w, h)\n",
    "\n",
    "            if captured and top_matches:\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                best_name, best_sim = top_matches[0]\n",
    "                label = f\"{best_name} ({best_sim*100:.1f}%)\"\n",
    "                (label_width, label_height), baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)\n",
    "                cv2.rectangle(frame, (x, y - label_height - baseline - 5), (x + label_width, y), (0, 255, 0), cv2.FILLED)\n",
    "                cv2.putText(frame, label, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)\n",
    "            else:\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 255), 2)\n",
    "\n",
    "        cv2.imshow('Face Recognition with MTCNN + FaceNet', frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    video.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3767b865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📷 Press 'q' to quit...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\n",
      "Captured face after being still for 2 seconds:\n",
      "  24WMR08866: 76.20% similarity\n",
      "  24WMR08863: 59.62% similarity\n",
      "  24WMR08861: 51.47% similarity\n"
     ]
    }
   ],
   "source": [
    "real_time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd2322a",
   "metadata": {},
   "source": [
    "# Model Evaluation for Face Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46c0a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_37092\\3695888952.py:26: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  embeddings_insight = pickle.load(f)\n",
      "c:\\Users\\User\\anaconda3\\envs\\environment\\Lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py:121: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\User/.insightface\\models\\buffalo_m\\1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\User/.insightface\\models\\buffalo_m\\2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\User/.insightface\\models\\buffalo_m\\det_2.5g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\User/.insightface\\models\\buffalo_m\\genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\User/.insightface\\models\\buffalo_m\\w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (640, 640)\n",
      "[insightface] GT: Jesmine, Pred: Jesmine, File: jesmine_1.jpg\n",
      "[insightface] GT: Jesmine, Pred: Jesmine, File: jesmine_10.jpg\n",
      "[insightface] GT: Jesmine, Pred: Jesmine, File: jesmine_2.jpg\n",
      "[insightface] GT: Jesmine, Pred: Jesmine, File: jesmine_3.jpg\n",
      "[insightface] GT: Jesmine, Pred: Jesmine, File: jesmine_4.jpg\n",
      "[insightface] GT: Jesmine, Pred: Jesmine, File: jesmine_5.jpg\n",
      "[insightface] GT: Jesmine, Pred: Jesmine, File: jesmine_6.jpg\n",
      "[insightface] GT: Jesmine, Pred: Jesmine, File: jesmine_7.jpg\n",
      "[insightface] GT: Jesmine, Pred: Jesmine, File: jesmine_8.jpg\n",
      "[insightface] GT: Jesmine, Pred: Jesmine, File: jesmine_9.jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "[mtcnn] GT: Jesmine, Pred: Unknown, File: jesmine_1.jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "[mtcnn] GT: Jesmine, Pred: Unknown, File: jesmine_10.jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "[mtcnn] GT: Jesmine, Pred: Unknown, File: jesmine_2.jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "[mtcnn] GT: Jesmine, Pred: Unknown, File: jesmine_3.jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "[mtcnn] GT: Jesmine, Pred: Unknown, File: jesmine_4.jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "[mtcnn] GT: Jesmine, Pred: Unknown, File: jesmine_5.jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "[mtcnn] GT: Jesmine, Pred: Unknown, File: jesmine_6.jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "[mtcnn] GT: Jesmine, Pred: Unknown, File: jesmine_7.jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "[mtcnn] GT: Jesmine, Pred: Unknown, File: jesmine_8.jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "[mtcnn] GT: Jesmine, Pred: Unknown, File: jesmine_9.jpg\n",
      "\n",
      "Accuracy Comparison Table:\n",
      " Person  InsightFace Accuracy  MTCNN+FaceNet Accuracy\n",
      "Jesmine                   1.0                     0.0\n",
      "Overall                   1.0                     0.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from insightface.app import FaceAnalysis\n",
    "from mtcnn import MTCNN\n",
    "from keras_facenet import FaceNet\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "name_to_id = {\n",
    "    \"Ethel\": \"24WMR08861\",\n",
    "    \"Jesmine\": \"24WMR08866\",\n",
    "    \"Khaili\": \"24WMR08863\",\n",
    "    \"Kit\": \"24WMR08870\"\n",
    "}\n",
    "id_to_name = {v: k for k, v in name_to_id.items()}\n",
    "\n",
    "with open(\"database/face_embeddings.pkl\", \"rb\") as f:\n",
    "    embeddings_insight = pickle.load(f)\n",
    "\n",
    "with open(\"database/facenet_embeddings.pkl\", \"rb\") as f:\n",
    "    embeddings_facenet = pickle.load(f)\n",
    "\n",
    "insight_detector = FaceAnalysis(name=\"buffalo_m\", providers=['CUDAExecutionProvider'])\n",
    "insight_detector.prepare(ctx_id=0, det_size=(640, 640))\n",
    "\n",
    "mtcnn_detector = MTCNN()\n",
    "facenet = FaceNet()\n",
    "\n",
    "def get_face_embedding_from_obj(face_obj):\n",
    "    emb = face_obj.embedding\n",
    "    if emb is None:\n",
    "        return None\n",
    "    return emb / np.linalg.norm(emb)\n",
    "\n",
    "def recognize_face(embedding, dataset, threshold=0.5):\n",
    "    if embedding is None:\n",
    "        return None, None, -1\n",
    "\n",
    "    best_score = -1\n",
    "    best_id, best_name = None, None\n",
    "\n",
    "    for entry in dataset:\n",
    "        db_embedding = entry[\"embedding\"]\n",
    "        db_embedding = db_embedding / np.linalg.norm(db_embedding)\n",
    "\n",
    "        cos_sim = np.dot(embedding, db_embedding)\n",
    "        if cos_sim > best_score:\n",
    "            best_score = cos_sim\n",
    "            best_id = entry[\"id\"]\n",
    "            best_name = entry[\"image_name\"]\n",
    "\n",
    "    if best_score < threshold:\n",
    "        return None, None, best_score\n",
    "\n",
    "    return best_id, best_name, best_score\n",
    "\n",
    "def get_top_matches(face_img, database, top_n=1, threshold=0.5):\n",
    "    face_img_rgb = cv2.cvtColor(face_img, cv2.COLOR_BGR2RGB)\n",
    "    embeddings = facenet.embeddings([face_img_rgb])\n",
    "    if embeddings is None or len(embeddings) == 0:\n",
    "        return []\n",
    "\n",
    "    query_emb = embeddings[0] / np.linalg.norm(embeddings[0])\n",
    "\n",
    "    scores = []\n",
    "    for entry in database:\n",
    "        db_embedding = entry[\"embedding\"]\n",
    "        db_embedding = db_embedding / np.linalg.norm(db_embedding)\n",
    "        cos_sim = np.dot(query_emb, db_embedding)\n",
    "        scores.append((entry[\"id\"], cos_sim))\n",
    "\n",
    "    scores = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "    return [s for s in scores if s[1] >= threshold][:top_n]\n",
    "\n",
    "def evaluate_model(test_dir, method=\"insightface\", threshold=0.5):\n",
    "    y_true, y_pred = [], []\n",
    "\n",
    "    if method == \"insightface\":\n",
    "        database = embeddings_insight\n",
    "    elif method == \"mtcnn\":\n",
    "        database = embeddings_facenet\n",
    "    else:\n",
    "        raise ValueError(\"Invalid method. Use 'insightface' or 'mtcnn'.\")\n",
    "\n",
    "    for person_name in os.listdir(test_dir):\n",
    "        person_path = os.path.join(test_dir, person_name)\n",
    "        if not os.path.isdir(person_path):\n",
    "            continue\n",
    "\n",
    "        for img_file in os.listdir(person_path):\n",
    "            if not img_file.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "                continue\n",
    "\n",
    "            img_path = os.path.join(person_path, img_file)\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                continue\n",
    "\n",
    "            pred_name = \"Unknown\"\n",
    "\n",
    "            # ---------------- INSIGHTFACE ----------------\n",
    "            if method == \"insightface\":\n",
    "                faces = insight_detector.get(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "                if not faces:\n",
    "                    continue\n",
    "                best_face = max(faces, key=lambda f: f.det_score)\n",
    "                emb = get_face_embedding_from_obj(best_face)\n",
    "                pid, name, score = recognize_face(emb, database, threshold)\n",
    "\n",
    "                pred_name = id_to_name.get(pid, \"Unknown\") if pid else \"Unknown\"\n",
    "\n",
    "            # ---------------- MTCNN + FACENET ----------------\n",
    "            elif method == \"mtcnn\":\n",
    "                results = mtcnn_detector.detect_faces(img)\n",
    "                if len(results) == 0:\n",
    "                    continue\n",
    "                largest = max(results, key=lambda r: r['box'][2] * r['box'][3])\n",
    "                x, y, w, h = largest['box']\n",
    "                x, y = max(0, x), max(0, y)\n",
    "                face_img = img[y:y+h, x:x+w]\n",
    "\n",
    "                try:\n",
    "                    top_matches = get_top_matches(face_img, database, top_n=1, threshold=threshold)\n",
    "                except:\n",
    "                    top_matches = []\n",
    "\n",
    "                if top_matches:\n",
    "                    matched_id = top_matches[0][0]\n",
    "                    pred_name = id_to_name.get(matched_id, \"Unknown\")\n",
    "                else:\n",
    "                    pred_name = \"Unknown\"\n",
    "\n",
    "            gt_name = person_name\n",
    "            y_true.append(gt_name)\n",
    "            y_pred.append(pred_name)\n",
    "\n",
    "            print(f\"[{method}] GT: {gt_name}, Pred: {pred_name}, File: {img_file}\")\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    return acc, y_true, y_pred\n",
    "\n",
    "test_dir = \"test_photos\"\n",
    "\n",
    "acc_insight, y_true_insight, y_pred_insight = evaluate_model(test_dir, method=\"insightface\", threshold=0.5)\n",
    "acc_mtcnn, y_true_mtcnn, y_pred_mtcnn = evaluate_model(test_dir, method=\"mtcnn\", threshold=0.5)\n",
    "\n",
    "persons = sorted(set(y_true_insight))\n",
    "data = []\n",
    "for person in persons:\n",
    "    mask_insight = [gt == person for gt in y_true_insight]\n",
    "    acc_person_insight = accuracy_score(\n",
    "        np.array(y_true_insight)[mask_insight], \n",
    "        np.array(y_pred_insight)[mask_insight]\n",
    "    )\n",
    "\n",
    "    mask_mtcnn = [gt == person for gt in y_true_mtcnn]\n",
    "    acc_person_mtcnn = accuracy_score(\n",
    "        np.array(y_true_mtcnn)[mask_mtcnn], \n",
    "        np.array(y_pred_mtcnn)[mask_mtcnn]\n",
    "    )\n",
    "\n",
    "    data.append([person, acc_person_insight, acc_person_mtcnn])\n",
    "\n",
    "data.append([\"Overall\", acc_insight, acc_mtcnn])\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"Person\", \"InsightFace Accuracy\", \"MTCNN+FaceNet Accuracy\"])\n",
    "print(\"\\nAccuracy Comparison Table:\")\n",
    "print(df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e9a1fd",
   "metadata": {},
   "source": [
    "# Barcode Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a29b1c4",
   "metadata": {},
   "source": [
    "## Gan Khai Li - zxing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "050e5fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-barcode in c:\\users\\user\\anaconda3\\envs\\environment\\lib\\site-packages (0.16.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\user\\anaconda3\\envs\\environment\\lib\\site-packages (11.2.1)\n",
      "Requirement already satisfied: zxing-cpp in c:\\users\\user\\anaconda3\\envs\\environment\\lib\\site-packages (2.3.0)\n",
      "Requirement already satisfied: qrcode in c:\\users\\user\\anaconda3\\envs\\environment\\lib\\site-packages (8.2)\n",
      "Collecting yagmail\n",
      "  Downloading yagmail-0.15.293-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from qrcode) (0.4.6)\n",
      "Collecting premailer (from yagmail)\n",
      "  Downloading premailer-3.10.0-py2.py3-none-any.whl.metadata (15 kB)\n",
      "Collecting lxml (from premailer->yagmail)\n",
      "  Downloading lxml-6.0.1-cp312-cp312-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting cssselect (from premailer->yagmail)\n",
      "  Downloading cssselect-1.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting cssutils (from premailer->yagmail)\n",
      "  Downloading cssutils-2.11.1-py3-none-any.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\envs\\environment\\lib\\site-packages (from premailer->yagmail) (2.32.3)\n",
      "Collecting cachetools (from premailer->yagmail)\n",
      "  Downloading cachetools-6.2.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting more-itertools (from cssutils->premailer->yagmail)\n",
      "  Downloading more_itertools-10.7.0-py3-none-any.whl.metadata (37 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\envs\\environment\\lib\\site-packages (from requests->premailer->yagmail) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\envs\\environment\\lib\\site-packages (from requests->premailer->yagmail) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\envs\\environment\\lib\\site-packages (from requests->premailer->yagmail) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\envs\\environment\\lib\\site-packages (from requests->premailer->yagmail) (2025.4.26)\n",
      "Downloading yagmail-0.15.293-py2.py3-none-any.whl (17 kB)\n",
      "Downloading premailer-3.10.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading cachetools-6.2.0-py3-none-any.whl (11 kB)\n",
      "Downloading cssselect-1.3.0-py3-none-any.whl (18 kB)\n",
      "Downloading cssutils-2.11.1-py3-none-any.whl (385 kB)\n",
      "Downloading lxml-6.0.1-cp312-cp312-win_amd64.whl (4.0 MB)\n",
      "   ---------------------------------------- 0.0/4.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/4.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.5/4.0 MB 1.9 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 0.8/4.0 MB 1.8 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 1.3/4.0 MB 2.0 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 1.6/4.0 MB 2.1 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 2.1/4.0 MB 2.1 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 2.6/4.0 MB 2.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 3.1/4.0 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  3.9/4.0 MB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.0/4.0 MB 2.3 MB/s eta 0:00:00\n",
      "Downloading more_itertools-10.7.0-py3-none-any.whl (65 kB)\n",
      "Installing collected packages: more-itertools, lxml, cssselect, cachetools, cssutils, premailer, yagmail\n",
      "Successfully installed cachetools-6.2.0 cssselect-1.3.0 cssutils-2.11.1 lxml-6.0.1 more-itertools-10.7.0 premailer-3.10.0 yagmail-0.15.293\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-barcode Pillow zxing-cpp qrcode yagmail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081834ed",
   "metadata": {},
   "source": [
    "Generate all barcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6827b42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All 54 barcodes generated successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import barcode\n",
    "from barcode.writer import ImageWriter\n",
    "import os\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"dataset/dataset.csv\")\n",
    "\n",
    "# Create output folder for barcodes\n",
    "output_dir = \"database/barcode_zxing\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "count = 0  # counter\n",
    "\n",
    "Code128 = barcode.get_barcode_class(\"code128\")\n",
    "\n",
    "# Loop through each student and generate barcode\n",
    "for idx, student in df.iterrows():\n",
    "    student_id = str(student[\"StudentID\"])  # ensure string\n",
    "    name = student[\"Name\"].replace(\" \", \"_\")  # safe filename\n",
    "    \n",
    "    # Instantiate the barcode with data\n",
    "    code128 = Code128(student_id, writer=ImageWriter())\n",
    "    \n",
    "    # Save barcode as PNG\n",
    "    filename = os.path.join(output_dir, f\"{student_id}_{name}\")\n",
    "    code128.save(filename)\n",
    "    \n",
    "    count += 1  # increment counter\n",
    "\n",
    "# Final confirmation\n",
    "print(f\"All {count} barcodes generated successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6bcf1e",
   "metadata": {},
   "source": [
    "Scan student ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60e9de7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graduation QR System initialized.\n",
      "Please present your Student ID barcode in the highlighted area. (Press 'q' to exit)\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[<zxingcpp.Barcode object at 0x000001D7BB9EA530>]\n",
      "Student ID detected: 2000116582\n",
      "Invalid Student ID: 2000116582\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import zxingcpp\n",
    "import qrcode\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv(\"dataset/dataset.csv\")\n",
    "student_dict = df.set_index(\"StudentID\").to_dict(\"index\")\n",
    "\n",
    "# Graduation classification function\n",
    "def graduation_level(cgpa):\n",
    "    if cgpa >= 3.67:\n",
    "        return \"Distinction\"\n",
    "    elif cgpa >= 2.67:\n",
    "        return \"Merit\"\n",
    "    elif cgpa >= 2.0:\n",
    "        return \"Pass\"\n",
    "    else:\n",
    "        return \"Fail\"\n",
    "\n",
    "# Open camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "\n",
    "target_w, target_h = 402, 280\n",
    "ret, frame = cap.read()\n",
    "h, w, _ = frame.shape\n",
    "roi_w_ratio = target_w / w\n",
    "roi_h_ratio = target_h / h\n",
    "\n",
    "print(\"Graduation QR System initialized.\")\n",
    "print(\"Please present your Student ID barcode in the highlighted area. (Press 'q' to exit)\")\n",
    "\n",
    "display_name = \"Awaiting scan...\"\n",
    "display_id = \"\"\n",
    "valid_student = False\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    h, w, _ = frame.shape\n",
    "    roi_w = int(w * roi_w_ratio)\n",
    "    roi_h = int(h * roi_h_ratio)\n",
    "    roi_x1 = w // 2 - roi_w // 2\n",
    "    roi_y1 = h // 2 - roi_h // 2\n",
    "    roi_x2 = roi_x1 + roi_w\n",
    "    roi_y2 = roi_y1 + roi_h\n",
    "\n",
    "    # Semi-transparent overlay\n",
    "    overlay = frame.copy()\n",
    "    overlay[:] = (0, 0, 0)\n",
    "    frame = cv2.addWeighted(overlay, 0.6, frame, 0.4, 0)\n",
    "    ret2, raw_frame = cap.read()\n",
    "    if ret2:\n",
    "        frame[roi_y1:roi_y2, roi_x1:roi_x2] = raw_frame[roi_y1:roi_y2, roi_x1:roi_x2]\n",
    "\n",
    "    # ROI decoding (barcode)\n",
    "    roi = frame[roi_y1:roi_y2, roi_x1:roi_x2]\n",
    "    gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    results = zxingcpp.read_barcodes(gray)\n",
    "    print(results)\n",
    "\n",
    "    if results:\n",
    "        student_id = results[0].text.strip()\n",
    "        print(f\"Student ID detected: {student_id}\")\n",
    "\n",
    "        if student_id in student_dict:\n",
    "            info = student_dict[student_id]\n",
    "            display_name = info['Name']\n",
    "            display_id = student_id\n",
    "            valid_student = True\n",
    "        else:\n",
    "            display_name = \"INVALID BARCODE\"\n",
    "            display_id = \"\"\n",
    "            valid_student = False\n",
    "\n",
    "    # Show Name and ID below ROI\n",
    "    cv2.putText(frame, f\"Name: {display_name}\", (roi_x1, roi_y2 + 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0) if valid_student else (0, 0, 255), 2)\n",
    "    cv2.putText(frame, f\"ID: {display_id}\", (roi_x1, roi_y2 + 70),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0) if valid_student else (0, 0, 255), 2)\n",
    "\n",
    "    # ROI box\n",
    "    cv2.rectangle(frame, (roi_x1, roi_y1), (roi_x2, roi_y2), (255, 0, 0), 3)\n",
    "    cv2.imshow(\"Graduation Barcode System - Student Verification\", frame)\n",
    "\n",
    "    if valid_student:\n",
    "        # Generate student QR code (with info + graduation level, but without CGPA)\n",
    "        level = graduation_level(info[\"CGPA\"])\n",
    "        qr_data = f\"ID: {student_id}\\nName: {info['Name']}\\nFaculty: {info['Faculty']}\\nGraduation Level: {level}\"\n",
    "\n",
    "        qr = qrcode.QRCode(box_size=10, border=4)\n",
    "        qr.add_data(qr_data)\n",
    "        qr.make(fit=True)\n",
    "        qr_img = qr.make_image(fill_color=\"black\", back_color=\"white\").convert(\"RGB\")\n",
    "        qr_np = np.array(qr_img)\n",
    "\n",
    "        # Save QR code locally (optional)\n",
    "        os.makedirs(\"QR_codes\", exist_ok=True)\n",
    "        qr_path = f\"QR_codes/{student_id}.png\"\n",
    "        qr_img.save(qr_path)\n",
    "        print(f\"QR code created for {info['Name']} ({student_id})\")\n",
    "        print(f\"File path: {qr_path}\")\n",
    "\n",
    "        # Display QR Code on screen for 20 seconds\n",
    "        start_time = time.time()\n",
    "        while True:\n",
    "            cv2.imshow(\"Graduation QR Code - Please capture this code\", qr_np)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "            if time.time() - start_time > 20:\n",
    "                break\n",
    "        break\n",
    "\n",
    "    elif results and student_id not in student_dict:\n",
    "        # Invalid barcode\n",
    "        cv2.putText(frame, \"Access Denied - Student not recognized as graduate\", (50, 100),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 0, 255), 3)\n",
    "        cv2.imshow(\"Graduation Barcode System - Student Verification\", frame)\n",
    "        print(f\"Invalid Student ID: {student_id}\")\n",
    "        cv2.waitKey(3000)\n",
    "        break\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a8beb3",
   "metadata": {},
   "source": [
    "Scan barcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d30eb9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scan student QR code (Press 'q' to quit)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import zxingcpp\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Load CSV (must contain: StudentID, Name, Photo, etc.)\n",
    "df = pd.read_csv(\"dataset/dataset.csv\")\n",
    "student_dict = df.set_index(\"StudentID\").to_dict(\"index\")\n",
    "\n",
    "# Open camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "\n",
    "# Target region size\n",
    "target_w, target_h = 402, 280\n",
    "ret, frame = cap.read()\n",
    "h, w, _ = frame.shape\n",
    "roi_w_ratio = target_w / w\n",
    "roi_h_ratio = target_h / h\n",
    "\n",
    "print(\"Scan student QR code (Press 'q' to quit)\")\n",
    "\n",
    "detected = False  # whether a valid QR code has been detected\n",
    "\n",
    "while True:\n",
    "    if detected:\n",
    "        # If a valid QR code has already been detected,\n",
    "        # stop reading from camera and only display details window\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "        continue\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Define region of interest (ROI) in the center\n",
    "    h, w, _ = frame.shape\n",
    "    roi_w = int(w * roi_w_ratio)\n",
    "    roi_h = int(h * roi_h_ratio)\n",
    "    roi_x1 = w // 2 - roi_w // 2\n",
    "    roi_y1 = h // 2 - roi_h // 2\n",
    "    roi_x2 = roi_x1 + roi_w\n",
    "    roi_y2 = roi_y1 + roi_h\n",
    "\n",
    "    # Create semi-transparent overlay\n",
    "    overlay = frame.copy()\n",
    "    overlay[:] = (0, 0, 0)\n",
    "    frame = cv2.addWeighted(overlay, 0.6, frame, 0.4, 0)\n",
    "\n",
    "    # Keep the ROI area clear\n",
    "    ret2, raw_frame = cap.read()\n",
    "    if ret2:\n",
    "        frame[roi_y1:roi_y2, roi_x1:roi_x2] = raw_frame[roi_y1:roi_y2, roi_x1:roi_x2]\n",
    "\n",
    "    # Decode QR inside ROI\n",
    "    roi = frame[roi_y1:roi_y2, roi_x1:roi_x2]\n",
    "    gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    results = zxingcpp.read_barcodes(gray)\n",
    "\n",
    "    display_name = \"Waiting for scan...\"\n",
    "    display_id = \"\"\n",
    "    valid_student = False\n",
    "\n",
    "    if results:\n",
    "        qr_data = results[0].text.strip()\n",
    "        print(\"QR Data:\", qr_data)\n",
    "\n",
    "        if \"ID:\" in qr_data:\n",
    "            student_id = qr_data.split(\"ID:\")[1].split(\"\\n\")[0].strip()\n",
    "            display_id = student_id\n",
    "\n",
    "            if student_id in student_dict:\n",
    "                info = student_dict[student_id]\n",
    "                display_name = info['Name']\n",
    "                valid_student = True\n",
    "                detected = True  # stop further camera reading once valid QR is found\n",
    "\n",
    "                # Create a new window to show photo + QR info\n",
    "                details_img = np.ones((500, 400, 3), dtype=np.uint8) * 255  # white background\n",
    "\n",
    "                # Load student photo\n",
    "                photo_path = info['Photo']\n",
    "                if os.path.exists(photo_path):\n",
    "                    student_img = cv2.imread(photo_path)\n",
    "                    student_img = cv2.resize(student_img, (200, 200))\n",
    "                    details_img[20:220, 100:300] = student_img\n",
    "\n",
    "                # Write QR content\n",
    "                y_offset = 250\n",
    "                for line in qr_data.split(\"\\n\"):\n",
    "                    cv2.putText(details_img, line, (20, y_offset),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2)\n",
    "                    y_offset += 30\n",
    "\n",
    "                cv2.imshow(\"Student Details\", details_img)\n",
    "            else:\n",
    "                display_name = \"INVALID QR\"\n",
    "                valid_student = False\n",
    "\n",
    "    # Display student name and ID on camera window\n",
    "    cv2.putText(frame, f\"Name: {display_name}\", (roi_x1, roi_y2 + 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0) if valid_student else (0, 0, 255), 2)\n",
    "    cv2.putText(frame, f\"ID: {display_id}\", (roi_x1, roi_y2 + 70),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0) if valid_student else (0, 0, 255), 2)\n",
    "\n",
    "    # Draw ROI box\n",
    "    cv2.rectangle(frame, (roi_x1, roi_y1), (roi_x2, roi_y2), (255, 0, 0), 3)\n",
    "    cv2.imshow(\"Student QR Code Scanner\", frame)\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2b96c1",
   "metadata": {},
   "source": [
    "## Kit Chin Jie Ying - PyZbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14d51a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyttsx3 in c:\\users\\user\\anaconda3\\envs\\environment\\lib\\site-packages (2.99)\n",
      "Collecting pyzbar\n",
      "  Downloading pyzbar-0.1.9-py2.py3-none-win_amd64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: comtypes in c:\\users\\user\\anaconda3\\envs\\environment\\lib\\site-packages (from pyttsx3) (1.4.11)\n",
      "Requirement already satisfied: pypiwin32 in c:\\users\\user\\anaconda3\\envs\\environment\\lib\\site-packages (from pyttsx3) (223)\n",
      "Requirement already satisfied: pywin32 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from pyttsx3) (306)\n",
      "Downloading pyzbar-0.1.9-py2.py3-none-win_amd64.whl (817 kB)\n",
      "   ---------------------------------------- 0.0/817.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/817.4 kB ? eta -:--:--\n",
      "   ------------ --------------------------- 262.1/817.4 kB ? eta -:--:--\n",
      "   ------------------------- -------------- 524.3/817.4 kB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 817.4/817.4 kB 2.1 MB/s eta 0:00:00\n",
      "Installing collected packages: pyzbar\n",
      "Successfully installed pyzbar-0.1.9\n"
     ]
    }
   ],
   "source": [
    "!pip install pyttsx3 pyzbar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86182303",
   "metadata": {},
   "source": [
    "Generate barcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a5beef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student Barcode is generated successful and store in database/barcode_zbar.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import barcode\n",
    "from barcode.writer import ImageWriter\n",
    "\n",
    "def generate_barcode(data: str, out_png_path: str, code_type: str = \"code128\") -> str:\n",
    "    folder = os.path.dirname(out_png_path)\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    base_no_ext, _ = os.path.splitext(out_png_path)\n",
    "    code = barcode.get(code_type, str(data), writer=ImageWriter())\n",
    "    return code.save(base_no_ext)\n",
    "\n",
    "def prepare_barcodes(input_csv, output_csv, barcode_folder=\"student_barcodes\"):\n",
    "    df = pd.read_csv(input_csv)\n",
    "\n",
    "    if \"StudentID\" not in df.columns:\n",
    "        raise ValueError(\"CSV dont have row 'StudentID'.\")\n",
    "\n",
    "    os.makedirs(barcode_folder, exist_ok=True)\n",
    "\n",
    "    df[\"Barcode_File\"] = \"\"\n",
    "    for idx, row in df.iterrows():\n",
    "        sid = str(row[\"StudentID\"]).strip()\n",
    "        filename = os.path.join(barcode_folder, f\"{sid}.png\")\n",
    "        barcode_path = generate_barcode(sid, filename)\n",
    "        df.at[idx, \"Barcode_File\"] = barcode_path\n",
    "\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"Student Barcode is generated successful and store in {output_csv}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    prepare_barcodes(\n",
    "        input_csv=\"dataset/dataset.csv\",\n",
    "        output_csv=\"database/barcode_zbar.csv\",\n",
    "        barcode_folder=\"database/barcode_zbar\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6319bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scan StudentID (press 'q' to exit)\n",
      "Detected StudentID: 2000116582\n",
      "Invalid StudentID\n",
      "Detected StudentID: 2000116582\n",
      "Invalid StudentID\n",
      "Detected StudentID: 2000116582\n",
      "Invalid StudentID\n",
      "Detected StudentID: 2000116582\n",
      "Invalid StudentID\n",
      "Detected StudentID: 2000116582\n",
      "Invalid StudentID\n",
      "Detected StudentID: 2000116582\n",
      "Invalid StudentID\n",
      "Detected StudentID: 2000116582\n",
      "Invalid StudentID\n",
      "Detected StudentID: 2000116582\n",
      "Invalid StudentID\n",
      "Detected StudentID: 2000116582\n",
      "Invalid StudentID\n",
      "Detected StudentID: 2000116582\n",
      "Invalid StudentID\n",
      "Detected StudentID: 2000116582\n",
      "Invalid StudentID\n",
      "Detected StudentID: 2000116582\n",
      "Invalid StudentID\n",
      "Detected StudentID: 2000116582\n",
      "Invalid StudentID\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2 as cv\n",
    "import pandas as pd\n",
    "import qrcode\n",
    "import re\n",
    "import time\n",
    "from pyzbar import pyzbar\n",
    "import numpy as np\n",
    "\n",
    "def safe_filename(s: str) -> str:\n",
    "    return re.sub(r'[\\\\/:*?\"<>|]+', \"_\", s)\n",
    "\n",
    "def generate_qr(data: str, out_file: str):\n",
    "    qr = qrcode.QRCode(version=1, box_size=10, border=4)\n",
    "    qr.add_data(data)\n",
    "    qr.make(fit=True)\n",
    "    qr.make_image(fill=\"black\", back_color=\"white\").save(out_file)\n",
    "\n",
    "def attendance_check(csv_path, qr_csv, qr_folder=\"student_qrcodes\"):\n",
    "    os.makedirs(qr_folder, exist_ok=True)\n",
    "\n",
    "    if os.path.exists(qr_csv):\n",
    "        df = pd.read_csv(qr_csv)\n",
    "    else:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        if \"QRCodePath\" not in df.columns:\n",
    "            df[\"QRCodePath\"] = \"\"\n",
    "\n",
    "    id_lookup = {str(r[\"StudentID\"]).strip(): r.to_dict() for _, r in df.iterrows()}\n",
    "    signed_ids = set()\n",
    "\n",
    "    cap = cv.VideoCapture(0, cv.CAP_DSHOW)\n",
    "    detector = pyzbar\n",
    "\n",
    "    print(\"Scan StudentID (press 'q' to exit)\")\n",
    "\n",
    "    last_qr_time = 0\n",
    "    showing_qr = False\n",
    "    qr_img = None\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            continue\n",
    "\n",
    "        # Convert to grayscale for faster decoding\n",
    "        gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "        barcodes = detector.decode(gray)\n",
    "\n",
    "        for bc in barcodes:\n",
    "            sid = bc.data.decode(\"utf-8\").strip()\n",
    "            print(f\"Detected StudentID: {sid}\")\n",
    "\n",
    "            if sid not in id_lookup:\n",
    "                print(\"Invalid StudentID\")\n",
    "                continue\n",
    "\n",
    "            row = id_lookup[sid]\n",
    "\n",
    "            if sid in signed_ids:\n",
    "                #Already scanned before\n",
    "                print(f\"{row['Name']} already attended.\")\n",
    "                continue\n",
    "            else:\n",
    "                #First scan → generate/show QR\n",
    "                qr_file = row.get(\"QRCodePath\", \"\")\n",
    "\n",
    "                # Handle NaN or invalid path\n",
    "                if pd.isna(qr_file):\n",
    "                    qr_file = \"\"\n",
    "\n",
    "                if not qr_file or not os.path.exists(str(qr_file)):\n",
    "                    content = (\n",
    "                        f\"Name: {row['Name']}\\n\"\n",
    "                        f\"StudentID: {row['StudentID']}\\n\"\n",
    "                        f\"Faculty: {row['Faculty']}\\n\"\n",
    "                        f\"Course: {row['Course']}\\n\"\n",
    "                        f\"CGPA: {row['CGPA']}\"\n",
    "                    )\n",
    "                    qr_file = os.path.join(qr_folder, f\"{sid}_{safe_filename(row['Name'])}.png\")\n",
    "                    generate_qr(content, qr_file)\n",
    "                    df.loc[df[\"StudentID\"].astype(str) == sid, \"QRCodePath\"] = qr_file\n",
    "                    df.to_csv(qr_csv, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "                qr_img = cv.imread(qr_file)\n",
    "                if qr_img is not None:\n",
    "                    showing_qr = True\n",
    "\n",
    "                    #Start countdown only after speech finishes\n",
    "                    last_qr_time = time.time()\n",
    "\n",
    "                signed_ids.add(sid)\n",
    "                print(f\"QR Ready: {qr_file}\")\n",
    "\n",
    "        if showing_qr and qr_img is not None:\n",
    "            elapsed = time.time() - last_qr_time\n",
    "            remaining = max(0, 10 - elapsed)\n",
    "\n",
    "            h, w = qr_img.shape[:2]\n",
    "            extra_space = 100\n",
    "            qr_display = np.ones((h + extra_space, w, 3), dtype=np.uint8) * 255\n",
    "            qr_display[0:h, 0:w] = qr_img\n",
    "\n",
    "            cv.putText(\n",
    "                qr_display,\n",
    "                f\"Countdown: {remaining:.1f} s\",\n",
    "                (10, h + 30),\n",
    "                cv.FONT_HERSHEY_SIMPLEX,\n",
    "                1.0,\n",
    "                (0, 0, 255),\n",
    "                2,\n",
    "                cv.LINE_AA\n",
    "            )\n",
    "\n",
    "            # Progress bar\n",
    "            bar_max_width = w - 20\n",
    "            bar_height = 20\n",
    "            bar_y = h + 60\n",
    "            cv.rectangle(qr_display, (10, bar_y), (10 + bar_max_width, bar_y + bar_height), (200, 200, 200), -1)\n",
    "            bar_width = int(bar_max_width * (remaining / 10))\n",
    "            cv.rectangle(qr_display, (10, bar_y), (10 + bar_width, bar_y + bar_height), (0, 0, 255), -1)\n",
    "\n",
    "            cv.imshow(\"QR Code\", qr_display)\n",
    "\n",
    "            if elapsed > 10:\n",
    "                cv.destroyWindow(\"QR Code\")\n",
    "                showing_qr = False\n",
    "                qr_img = None\n",
    "\n",
    "        cv.imshow(\"Attendance Check\", frame)\n",
    "        if cv.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    attendance_check(\n",
    "        csv_path=\"database/barcode_zbar.csv\",  \n",
    "        qr_csv=\"database/dataset_with_qrcode.csv\",     \n",
    "        qr_folder=\"zbar_qrcodes\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32e41df",
   "metadata": {},
   "source": [
    "Scan and display the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a59b387c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'database/dataset_with_qrcode.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 209\u001b[0m\n\u001b[0;32m    206\u001b[0m         cap\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    207\u001b[0m         cv\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n\u001b[1;32m--> 209\u001b[0m \u001b[43mscan_and_display_with_yolo_and_fallback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcsv_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdatabase/dataset_with_qrcode.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    211\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcamera_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwindow_title\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGraduation Screen\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogo_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstatic/images/logo.png\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m    214\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[15], line 93\u001b[0m, in \u001b[0;36mscan_and_display_with_yolo_and_fallback\u001b[1;34m(csv_path, camera_index, window_title, qr_class_name, conf, iou, pad, logo_path)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscan_and_display_with_yolo_and_fallback\u001b[39m(\n\u001b[0;32m     84\u001b[0m     csv_path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m     85\u001b[0m     camera_index: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     91\u001b[0m     logo_path: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     92\u001b[0m ):\n\u001b[1;32m---> 93\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m     has_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStudentID\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m     96\u001b[0m     id_lookup \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\environment\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\environment\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\environment\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\environment\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\environment\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'database/dataset_with_qrcode.csv'"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# --- Parse QR Code Text ---\n",
    "def parse_qr_text(qr_text: str) -> dict:\n",
    "    info = {}\n",
    "    for line in str(qr_text).splitlines():\n",
    "        m = re.match(r\"\\s*([^:]+)\\s*:\\s*(.*)\\s*$\", line)\n",
    "        if m:\n",
    "            key = m.group(1).strip()\n",
    "            val = m.group(2).strip()\n",
    "            info[key] = val\n",
    "    return info\n",
    "\n",
    "def _clip(v, lo, hi):\n",
    "    return max(lo, min(int(v), hi))\n",
    "\n",
    "# --- Info Panel Generator ---\n",
    "def make_info_panel(lines, photo_img=None, logo_img=None, panel_size=(480, 480)):\n",
    "    h, w = panel_size\n",
    "    panel = 255 * np.ones((h, w, 3), dtype=np.uint8)  # white background\n",
    "\n",
    "    # --- Add logo (with transparency support) ---\n",
    "    if logo_img is not None:\n",
    "        if logo_img.shape[2] == 4:  # if RGBA (has alpha)\n",
    "            lh, lw = logo_img.shape[:2]\n",
    "            scale = 60 / lh  # fixed height = 60px\n",
    "            new_w, new_h = int(lw * scale), int(lh * scale)\n",
    "            logo_resized = cv.resize(logo_img, (new_w, new_h), interpolation=cv.INTER_AREA)\n",
    "\n",
    "            # split channels\n",
    "            b, g, r, a = cv.split(logo_resized)\n",
    "            logo_rgb = cv.merge((b, g, r))\n",
    "            mask = a.astype(float) / 255.0\n",
    "\n",
    "            x_offset = (w - new_w) // 2\n",
    "            y_offset = 10\n",
    "\n",
    "            roi = panel[y_offset:y_offset+new_h, x_offset:x_offset+new_w]\n",
    "\n",
    "            # alpha blend\n",
    "            for c in range(3):\n",
    "                roi[:, :, c] = (1 - mask) * roi[:, :, c] + mask * logo_rgb[:, :, c]\n",
    "\n",
    "            panel[y_offset:y_offset+new_h, x_offset:x_offset+new_w] = roi\n",
    "\n",
    "        else:\n",
    "            # fallback if no alpha channel\n",
    "            lh, lw = logo_img.shape[:2]\n",
    "            scale = 60 / lh\n",
    "            new_w, new_h = int(lw * scale), int(lh * scale)\n",
    "            logo_resized = cv.resize(logo_img, (new_w, new_h), interpolation=cv.INTER_AREA)\n",
    "            x_offset = (w - new_w) // 2\n",
    "            panel[10:10+new_h, x_offset:x_offset+new_w] = logo_resized\n",
    "\n",
    "\n",
    "\n",
    "    # Draw student photo at top (centered)\n",
    "    if photo_img is not None:\n",
    "        ph, pw = photo_img.shape[:2]\n",
    "        scale = min((h // 3) / ph, (w - 40) / pw)  # max 1/3 of panel height\n",
    "        new_w, new_h = int(pw * scale), int(ph * scale)\n",
    "        photo_resized = cv.resize(photo_img, (new_w, new_h), interpolation=cv.INTER_AREA)\n",
    "        x_offset = (w - new_w) // 2\n",
    "        panel[80:80+new_h, x_offset:x_offset+new_w] = photo_resized\n",
    "        y_text = 80 + new_h + 20\n",
    "    else:\n",
    "        y_text = 100\n",
    "\n",
    "    # Draw info text neatly\n",
    "    for line in lines:\n",
    "        cv.putText(panel, line, (20, y_text), cv.FONT_HERSHEY_SIMPLEX, \n",
    "                   0.7, (0, 0, 0), 2, cv.LINE_AA)\n",
    "        y_text += 35\n",
    "\n",
    "    return panel\n",
    "\n",
    "# --- Main Function ---\n",
    "def scan_and_display_with_yolo_and_fallback(\n",
    "    csv_path: str,\n",
    "    camera_index: int = 0,\n",
    "    window_title: str = \"Graduation Screen\",\n",
    "    qr_class_name: str = \"qrcode\",\n",
    "    conf: float = 0.25,\n",
    "    iou: float = 0.45,\n",
    "    pad: int = 8,\n",
    "    logo_path: str = None\n",
    "):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    has_id = \"StudentID\" in df.columns\n",
    "\n",
    "    id_lookup = {}\n",
    "    if has_id:\n",
    "        id_lookup = {str(r[\"StudentID\"]).strip(): r.to_dict() for _, r in df.iterrows()}\n",
    "\n",
    "    csv_dir = os.path.dirname(os.path.abspath(csv_path))\n",
    "    model = YOLO(\"yolov8n.pt\")\n",
    "    names = model.names\n",
    "    name2id = {v: k for k, v in names.items()} if isinstance(names, dict) else {}\n",
    "\n",
    "    cap = cv.VideoCapture(camera_index, cv.CAP_DSHOW)\n",
    "    if not cap.isOpened():\n",
    "        raise RuntimeError(\"Cannot open camera\")\n",
    "\n",
    "    detector = cv.QRCodeDetector()\n",
    "    cv.namedWindow(window_title, cv.WINDOW_NORMAL)\n",
    "\n",
    "    logo_img = cv.imread(logo_path, cv.IMREAD_UNCHANGED) if logo_path else None\n",
    "    info_panel = make_info_panel([\"Waiting for QR Code...\"], logo_img=logo_img)\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            ok, frame = cap.read()\n",
    "            if not ok:\n",
    "                continue\n",
    "\n",
    "            h, w = frame.shape[:2]\n",
    "            data = None\n",
    "\n",
    "            # Step 1: YOLO detect QR\n",
    "            results = model(frame, conf=conf, iou=iou, verbose=False)\n",
    "            boxes = []\n",
    "            if results and len(results) > 0:\n",
    "                r0 = results[0]\n",
    "                if r0.boxes is not None and len(r0.boxes) > 0:\n",
    "                    xyxy = r0.boxes.xyxy.cpu().numpy()\n",
    "                    cls = r0.boxes.cls.cpu().numpy().astype(int)\n",
    "                    confs = r0.boxes.conf.cpu().numpy()\n",
    "                    for (x1, y1, x2, y2), c, cf in zip(xyxy, cls, confs):\n",
    "                        if qr_class_name in name2id and c != name2id[qr_class_name]:\n",
    "                            continue\n",
    "                        boxes.append((x1, y1, x2, y2, cf))\n",
    "\n",
    "            if boxes:\n",
    "                x1, y1, x2, y2, cf = max(boxes, key=lambda x: x[4])\n",
    "                x1p = _clip(x1 - pad, 0, w - 1)\n",
    "                y1p = _clip(y1 - pad, 0, h - 1)\n",
    "                x2p = _clip(x2 + pad, 0, w - 1)\n",
    "                y2p = _clip(y2 + pad, 0, h - 1)\n",
    "\n",
    "                roi = frame[y1p:y2p, x1p:x2p]\n",
    "                if roi.size > 0:\n",
    "                    data, _, _ = detector.detectAndDecode(roi)\n",
    "                    if not data:\n",
    "                        for scale in (1.5, 2.0):\n",
    "                            roi_big = cv.resize(roi, None, fx=scale, fy=scale, interpolation=cv.INTER_CUBIC)\n",
    "                            data, _, _ = detector.detectAndDecode(roi_big)\n",
    "                            if data:\n",
    "                                break\n",
    "\n",
    "                    if data:\n",
    "                        cv.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (36, 255, 12), 3)\n",
    "\n",
    "            if not data:\n",
    "                data, _, _ = detector.detectAndDecode(frame)\n",
    "\n",
    "            if data:\n",
    "                info = parse_qr_text(data)\n",
    "                lines = []\n",
    "                photo_img = None\n",
    "\n",
    "                if has_id and \"StudentID\" in info:\n",
    "                    sid = str(info[\"StudentID\"]).strip()\n",
    "                    row = id_lookup.get(sid)\n",
    "                    if row is not None:\n",
    "                        lines = [\n",
    "                            f\"Name: {row.get('Name','')}\",\n",
    "                            f\"Student ID: {row.get('StudentID','')}\",\n",
    "                            f\"Faculty: {row.get('Faculty','')}\",\n",
    "                            f\"Course: {row.get('Course','')}\",\n",
    "                            f\"CGPA: {row.get('CGPA','')}\",\n",
    "                            f\"Class: {row.get('CGPA_Class','')}\",\n",
    "                        ]\n",
    "                        if \"Photo\" in row and row[\"Photo\"]:\n",
    "                            photo_path = os.path.join(csv_dir, str(row[\"Photo\"]).replace(\"/\", os.sep))\n",
    "                            if os.path.exists(photo_path):\n",
    "                                photo_img = cv.imread(photo_path)\n",
    "                    else:\n",
    "                        lines = [f\"Unregistered Student ID: {sid}\"]\n",
    "                else:\n",
    "                    lines = [\n",
    "                        f\"Name: {info.get('Name','')}\",\n",
    "                        f\"Student ID: {info.get('StudentID','')}\",\n",
    "                        f\"Faculty: {info.get('Faculty','')}\",\n",
    "                        f\"Course: {info.get('Course','')}\",\n",
    "                        f\"CGPA: {info.get('CGPA','')}\",\n",
    "                        f\"Class: {info.get('Class','')}\",\n",
    "                    ]\n",
    "\n",
    "                info_panel = make_info_panel(lines, photo_img, logo_img)\n",
    "\n",
    "            cam_resized = cv.resize(frame, (640, 480))\n",
    "            info_resized = cv.resize(info_panel, (480, 480))\n",
    "            combined = np.hstack((cam_resized, info_resized))\n",
    "\n",
    "            cv.imshow(window_title, combined)\n",
    "            k = cv.waitKey(1) & 0xFF\n",
    "            if k == ord('q'):\n",
    "                break\n",
    "\n",
    "    finally:\n",
    "        cap.release()\n",
    "        cv.destroyAllWindows()\n",
    "\n",
    "scan_and_display_with_yolo_and_fallback(\n",
    "    csv_path=\"database/dataset_with_qrcode.csv\",\n",
    "    camera_index=0,\n",
    "    window_title=\"Graduation Screen\",\n",
    "    logo_path=\"static/images/logo.png\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81456d7",
   "metadata": {},
   "source": [
    "## Model Evaluation for Barcode Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095c4bd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab87a1ef",
   "metadata": {},
   "source": [
    "# Real Time Human Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c024f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ultralytics, deep-sort-realtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aefed7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next person\n",
      "Next person\n",
      "Next person\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import cv2 as cv\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "\n",
    "\n",
    "def track_person(model_path=\"yolov8n.pt\", threshold=0.4, camera_index=0):\n",
    "    # Load YOLO\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model = YOLO(model_path)\n",
    "    model.to(device)\n",
    "\n",
    "    # DeepSORT tracker\n",
    "    tracker = DeepSort(\n",
    "        max_age=30,\n",
    "        n_init=3,\n",
    "        max_iou_distance=0.7,\n",
    "        nms_max_overlap=1.0,\n",
    "        max_cosine_distance=0.2,\n",
    "        nn_budget=None,\n",
    "        embedder=\"mobilenet\",\n",
    "        half=torch.cuda.is_available(),\n",
    "        bgr=True,\n",
    "    )\n",
    "\n",
    "    def draw_box_with_label(img, tlbr, label, color=(0, 255, 0)):\n",
    "        x1, y1, x2, y2 = map(int, tlbr)\n",
    "        cv.rectangle(img, (x1, y1), (x2, y2), color, 2)\n",
    "        (tw, th), _ = cv.getTextSize(label, cv.FONT_HERSHEY_SIMPLEX, 0.6, 2)\n",
    "        cv.rectangle(img, (x1, y1 - th - 6), (x1 + tw + 6, y1), color, -1)\n",
    "        cv.putText(img, label, (x1 + 3, y1 - 6),\n",
    "                   cv.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2)\n",
    "\n",
    "    # Init video\n",
    "    video = cv.VideoCapture(camera_index)\n",
    "    fps_smooth = None\n",
    "    person_class_id = 0\n",
    "\n",
    "    # Accuracy tracking\n",
    "    prev_ids = {}\n",
    "    id_switches = 0\n",
    "    total_tracks = 0\n",
    "\n",
    "    # Right-to-left detection\n",
    "    # track_id → [first_x, last_x]\n",
    "    track_positions = {}\n",
    "\n",
    "    while True:\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame = cv.flip(frame, 1)\n",
    "        t0 = time.time()\n",
    "        h, w, _ = frame.shape\n",
    "\n",
    "        # Detect people\n",
    "        results = model.predict(frame, conf=threshold, iou=0.45,\n",
    "                                verbose=False, classes=[person_class_id], device=device)\n",
    "\n",
    "        detections = []\n",
    "        if len(results):\n",
    "            r = results[0]\n",
    "            if r.boxes is not None and len(r.boxes) > 0:\n",
    "                for box in r.boxes:\n",
    "                    xyxy = box.xyxy[0].cpu().numpy()\n",
    "                    conf = float(box.conf[0].cpu().numpy())\n",
    "                    detections.append([xyxy.tolist(), conf, \"person\"])\n",
    "\n",
    "        # Update tracker\n",
    "        tracks = tracker.update_tracks(detections, frame=frame)\n",
    "\n",
    "        for trk in tracks:\n",
    "            if not trk.is_confirmed() or trk.time_since_update > 0:\n",
    "                continue\n",
    "            track_id = trk.track_id\n",
    "            tlbr = trk.to_tlbr()\n",
    "            x1, y1, x2, y2 = map(int, tlbr)\n",
    "            cx = (x1 + x2) // 2  # center x\n",
    "\n",
    "            # Draw\n",
    "            draw_box_with_label(frame, tlbr, f\"ID {track_id}\")\n",
    "\n",
    "            # Accuracy check \n",
    "            total_tracks += 1\n",
    "            if track_id in prev_ids:\n",
    "                if prev_ids[track_id] != track_id:\n",
    "                    id_switches += 1\n",
    "            prev_ids[track_id] = track_id\n",
    "\n",
    "            # Movement Right -> Left\n",
    "            if track_id not in track_positions:\n",
    "                track_positions[track_id] = [cx, cx]\n",
    "            else:\n",
    "                track_positions[track_id][1] = cx\n",
    "\n",
    "                start_x, last_x = track_positions[track_id]\n",
    "\n",
    "                if start_x > 0.7 * w and last_x < 0.3 * w:\n",
    "                    print(\"Next person\")\n",
    "                    track_positions.pop(track_id) \n",
    "\n",
    "        # FPS\n",
    "        dt = time.time() - t0\n",
    "        fps = 1.0 / dt if dt > 0 else 0.0\n",
    "        fps_smooth = fps if fps_smooth is None else fps_smooth * 0.9 + fps * 0.1\n",
    "        cv.putText(frame, f\"FPS: {fps_smooth:.1f}\", (10, 30),\n",
    "                   cv.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 2)\n",
    "\n",
    "        # Accuracy display\n",
    "        if total_tracks > 0:\n",
    "            accuracy = 1 - (id_switches / total_tracks)\n",
    "            cv.putText(frame, f\"Accuracy: {accuracy:.2f}\", (10, 60),\n",
    "                       cv.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)\n",
    "\n",
    "        cv.imshow(\"Real Time Human Tracking\", frame)\n",
    "        if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    video.release()\n",
    "    cv.destroyAllWindows()\n",
    "\n",
    "track_person()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1a66f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
